{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ======================INICIO=DO=STATUS===========================================\n",
    "# 1. Instala as bibliotecas necess√°rias\n",
    "!pip install requests beautifulsoup4 --quiet\n",
    "!pip install gspread gspread-dataframe google-auth --quiet\n",
    "!pip install pymupdf --quiet\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import fitz  # pymupdf\n",
    "import tiktoken\n",
    "import time\n",
    "import gspread\n",
    "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
    "from google.colab import auth\n",
    "from google.auth import default\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. AUTENTICA√á√ÉO E CONFIGURA√á√ÉO DA API\n",
    "# ==============================================================================\n",
    "print(\"üîê Autenticando usu√°rio...\")\n",
    "auth.authenticate_user()\n",
    "creds, _ = default()\n",
    "gc = gspread.authorize(creds)\n",
    "drive = build('drive', 'v3', credentials=creds)\n",
    "print(\"‚úÖ Autentica√ß√£o conclu√≠da!\")\n",
    "\n",
    "# ==========================\n",
    "# CONFIGURA√á√ÉO DE PASTAS E PLANILHAS\n",
    "# ==========================\n",
    "PDF_DIR = \"/content/drive/MyDrive/Automa√ß√£o & Processos ‚Äì DMOE-SEDUC/Processo Notificat√≥rio/PDF\"\n",
    "PLANILHA_DIR = \"/content/drive/MyDrive/Automa√ß√£o & Processos ‚Äì DMOE-SEDUC/Processo Notificat√≥rio/Processo_Notificatorio_DMOE.gsheet\"\n",
    "GSHEET_NAME = os.path.splitext(os.path.basename(PLANILHA_DIR))[0]\n",
    "GSHEET_WORKSHEET_NAME = \"TABELA\"\n",
    "\n",
    "# ID DA PASTA DO DRIVE (Aquele que funcionou para voc√™)\n",
    "FOLDER_ID_DRIVE = \"1hl0liZWvMfr1GLzm9_PO9om_7fErJa_5\"\n",
    "\n",
    "# ======= MENSAGENS DE ERROS ========\n",
    "ERR_MSG_EXPEIDENTE = \"Sem Penalidade\"\n",
    "ERR_MSG_TIPO_PENALIDADE  = \"\"\n",
    "ERR_MSG_PERCENTUAL_MULTA  = \"\"\n",
    "ERR_MSG_IMPEDIMENTOS = \"\"\n",
    "ERR_MSG_PENALIDADE_MESES = \"\"\n",
    "ERR_MSG_DATA_PENALIZACAO = \"\"\n",
    "ERR_MSG_STATUS = \"ERRO: IMPOSSIVEL DE DEFINIR UM STATUS\"\n",
    "\n",
    "# ====== NOME DAS COLUNAS PADR√ÉO ======\n",
    "COLUMNS = [\n",
    "    \"numero_contrato\", \"nome_empresa\", \"cnpj_empresa\", \"proa_notificatorio\",\n",
    "    \"proa_mae\", \"status_processo\", \"valor_contrato_consolidado\",\n",
    "    \"tipo_penalidade\", \"percentual_multa\", \"valor_multa\", \"impedimentos\",\n",
    "    \"penalidade_meses\", \"data_penalizacao\", \"ultima_analise_feita\",\n",
    "    \"ultima_atualizacao_processo\"\n",
    "]\n",
    "\n",
    "# ==========================\n",
    "# FUN√á√ïES AUXILIARES DE TEXTO E REGEX\n",
    "# ==========================\n",
    "def extract_pdf_text(pdf_path: str) -> str:\n",
    "    \"\"\"Extrai TODO o texto do PDF p√°gina a p√°gina.\"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        pages_text = [page.get_text(\"text\") for page in doc]\n",
    "        doc.close()\n",
    "        return \"\\n\".join(pages_text)\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def _norm_text(s: str) -> str:\n",
    "    s = (s.replace(\"\\xa0\", \" \").replace(\"\\u2009\", \" \").replace(\"\\u200a\", \" \")\n",
    "           .replace(\"\\u200b\", \"\").replace(\"‚Äì\", \"-\").replace(\"‚Äî\", \"-\").replace(\"-\", \"-\"))\n",
    "    s = re.sub(r\"[ \\t]+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "def _extract_clean_proa(cell_value):\n",
    "    \"\"\"\n",
    "    Remove f√≥rmulas de HYPERLINK e retorna apenas os d√≠gitos do PROA.\n",
    "    Ex: '=HYPERLINK(\"...\"; \"23/1900-00...\")' -> '23190000...'\n",
    "    \"\"\"\n",
    "    val = str(cell_value)\n",
    "    # Se for f√≥rmula, tenta pegar o texto do segundo argumento\n",
    "    if val.startswith(\"=\"):\n",
    "        # Tenta quebrar por aspas duplas (o texto geralmente √© o √∫ltimo item entre aspas)\n",
    "        parts = val.split('\"')\n",
    "        if len(parts) >= 4:\n",
    "            # Pega o pen√∫ltimo elemento (geralmente o texto do link)\n",
    "            val = parts[-2]\n",
    "\n",
    "    # Retorna apenas n√∫meros\n",
    "    return re.sub(r\"\\D\", \"\", val)\n",
    "\n",
    "def _parse_br_date(date_str: str):\n",
    "    \"\"\"Converte string 'dd/mm/aaaa' para objeto date. Retorna None se falhar.\"\"\"\n",
    "    if not isinstance(date_str, str) or not date_str.strip():\n",
    "        return None\n",
    "    try:\n",
    "        # Pega apenas os 10 primeiros caracteres (dd/mm/aaaa)\n",
    "        clean_str = date_str.strip()[:10]\n",
    "        return datetime.datetime.strptime(clean_str, \"%d/%m/%Y\").date()\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def _clean_company_name(s: str) -> str:\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.strip(\" ,;.-\")\n",
    "\n",
    "def _flex_regex_escape(s: str) -> str:\n",
    "    return r\"\\s+\".join(re.escape(part) for part in s.split())\n",
    "\n",
    "def _slice_after_heading(text: str, heading: str, window: int = 1200) -> str:\n",
    "    heading_regex = _flex_regex_escape(heading)\n",
    "    m = re.search(heading_regex, text, flags=re.IGNORECASE)\n",
    "    if not m: return \"\"\n",
    "    start = m.end()\n",
    "    return text[start:start+window]\n",
    "\n",
    "# ==========================\n",
    "# FUN√á√ïES DE EXTRA√á√ÉO ESPEC√çFICAS\n",
    "# ==========================\n",
    "def get_situacao_processo_web(processo_id: str) -> str:\n",
    "    base_url = \"https://secweb.procergs.com.br/pra-aj4/public/proa_retorno_consulta_publica.xhtml\"\n",
    "    params = {\"numeroProcesso\": processo_id}\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "    situacao_padrao = \"ERRO: N√£o encontrado\"\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        situacao_label_tag = soup.find('label', string=re.compile(r\"Situa√ß√£o:\"))\n",
    "        if situacao_label_tag:\n",
    "            try:\n",
    "                parent_td = situacao_label_tag.find_parent('td')\n",
    "                value_td = parent_td.find_next_sibling('td')\n",
    "                val = value_td.get_text(strip=True)\n",
    "                return val if val else situacao_padrao\n",
    "            except: return \"ERRO: Falha no parse do HTML\"\n",
    "        else: return situacao_padrao\n",
    "    except: return \"ERRO: Falha na conex√£o/HTTP\"\n",
    "\n",
    "def get_numero_contrato(text: str) -> str:\n",
    "    padrao1 = r\"TERMO\\s+DE\\s+CONTRATO\\s+EMERGENCIAL\\s+DE\\s+OBRAS\\s+E\\s+SERVI[√áC]OS\\s+DE\\s+ENGENHARIA\\s*N[¬∫¬∞]?\\s*([0-9]{1,4}/[0-9]{4})\"\n",
    "    m = re.search(padrao1, text, flags=re.IGNORECASE)\n",
    "    if m: return m.group(1).strip()\n",
    "    padrao2 = r\"CONTRATO[^\\n]{0,120}?N[¬∫¬∞]?\\s*([0-9]{1,4}/[0-9]{4})\"\n",
    "    m2 = re.search(padrao2, text, flags=re.IGNORECASE)\n",
    "    if m2: return m2.group(1).strip()\n",
    "    return \"\"\n",
    "\n",
    "def get_nome_empresa(text: str) -> str:\n",
    "    texto_normalizado = _norm_text(text)\n",
    "\n",
    "    m = re.search(r\"inten√ß(?:√£o|ao)\\s+de\\s+instaurar\\s+procedimento\\s+notificat(?:√≥rio|orio)\\s+contra\\s+(?:a\\s+)?empresa\\s+(.+?)(?=[,;]|inscrita|CNPJ|sediada|$)\", texto_normalizado, flags=re.IGNORECASE | re.DOTALL)\n",
    "    if m: return _clean_company_name(m.group(1))\n",
    "\n",
    "    m2 = re.search(r\"contra\\s+(?:a\\s+)?empresa\\s*[,;]?\\s*(.+?)(?=[,;]|inscrita|CNPJ|sediada|$)\", texto_normalizado, flags=re.IGNORECASE | re.DOTALL)\n",
    "    if m2: return _clean_company_name(m2.group(1))\n",
    "\n",
    "    pages = texto_normalizado.split('\\x0c')\n",
    "    text_p1 = pages[0] if len(pages) > 1 else texto_normalizado[:3000]\n",
    "\n",
    "    m3 = re.search(r\"Empresa\\s*:\\s*(.+?)(?=\\n|Local:|CNPJ|Endere√ßo:|$)\", text_p1, flags=re.IGNORECASE)\n",
    "    if m3: return _clean_company_name(m3.group(1))\n",
    "\n",
    "    m4 = re.search(r\"Tipo\\s*:\\s*(.+?)\\s*-\\s*CTO\", text_p1, flags=re.IGNORECASE)\n",
    "    if m4: return _clean_company_name(m4.group(1))\n",
    "\n",
    "    return \"ERRO AO ENCONTRAR O NOME DA EMPRESA\"\n",
    "\n",
    "def get_cnpj_empresa(text: str) -> str:\n",
    "    CNPJ_SEDUC = \"92941681000100\"\n",
    "    texto_normalizado = _norm_text(text)\n",
    "    CNPJ_FLEX = r\"(\\d{2})\\s*[\\.\\-\\/]?\\s*(\\d{3})\\s*[\\.\\-\\/]?\\s*(\\d{3})\\s*[\\.\\-\\/]?\\s*(\\d{4})\\s*[\\.\\-\\/]?\\s*(\\d{2})\"\n",
    "    PREFIXOS = [r\"inscrita\\s+no\\s+minist[√©e]rio\\s+da\\s+fazenda\", r\"inscri[√ßc][√£a]o\\s+n[¬∫o]?\\s+cnpj\", r\"cnpj\\s*[:\\-]?\\s*\", r\"sob\\s+o\\s+n[¬∫o]?\\s*\"]\n",
    "\n",
    "    bloco = _slice_after_heading(texto_normalizado, \"TERMO DE ABERTURA\", window=3000) or texto_normalizado\n",
    "    nome = get_nome_empresa(texto_normalizado)\n",
    "\n",
    "    # 1. Tenta com ancora do nome\n",
    "    if nome and \"ERRO\" not in nome.upper():\n",
    "        nome_flex = re.escape(nome.strip()).replace(r\"\\ \", r\"\\s+\")\n",
    "        pattern = re.compile(rf\"empresa\\s+{nome_flex}\\s*[,;]?\\s*(?:{'|'.join(PREFIXOS)})\\s*{CNPJ_FLEX}\", re.IGNORECASE | re.DOTALL)\n",
    "        m = pattern.search(bloco)\n",
    "        if m:\n",
    "            d = \"\".join(m.groups())\n",
    "            if d != CNPJ_SEDUC: return f\"{d[:2]}.{d[2:5]}.{d[5:8]}/{d[8:12]}-{d[12:]}\"\n",
    "\n",
    "    # 2. Fallback\n",
    "    for prefixo in PREFIXOS:\n",
    "        pattern = re.compile(rf\"{prefixo}\\s*{CNPJ_FLEX}\", re.IGNORECASE | re.DOTALL)\n",
    "        for tb in [bloco, texto_normalizado]:\n",
    "            for m in pattern.finditer(tb):\n",
    "                d = \"\".join(m.groups())\n",
    "                if d != CNPJ_SEDUC: return f\"{d[:2]}.{d[2:5]}.{d[5:8]}/{d[8:12]}-{d[12:]}\"\n",
    "    return \"ERRO AO ENCONTRAR O CNPJ\"\n",
    "\n",
    "def get_proa_notificatorio(text: str):\n",
    "    ms = re.findall(r\"\\b(\\d{2}\\/\\d{4}-\\d{7}-\\d)\\b\", text)\n",
    "    return ms[0] if ms else \"\"\n",
    "\n",
    "def get_proa_mae(text: str, proa_atual: str):\n",
    "    all_proas = re.findall(r\"\\b(\\d{2}\\/\\d{4}-\\d{7}-\\d)\\b\", text)\n",
    "    candidates = [p for p in all_proas if p != proa_atual]\n",
    "    if not candidates: return \"\"\n",
    "    # Pega o mais antigo (menor ano)\n",
    "    candidates.sort(key=lambda p: int(p.split(\"/\")[0]) if p.split(\"/\")[0].isdigit() else 99)\n",
    "    return candidates[0]\n",
    "\n",
    "# --- Fun√ß√µes do Expediente ---\n",
    "def _build_proa_regex(proa_notif: str) -> str:\n",
    "    parts = re.split(r'[/-]', proa_notif)\n",
    "    if len(parts) != 4: return re.escape(proa_notif)\n",
    "    a, b, c, d = [p.strip() for p in parts]\n",
    "    return rf\"{a}\\s*/\\s*{b}\\s*-\\s*{c.lstrip('0')}\\s*-\\s*{d}\"\n",
    "\n",
    "def _find_expediente_page_index(pdf_path: str, proa_notif: str) -> int:\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        proa_pat = _build_proa_regex(proa_notif)\n",
    "        pat_header = re.compile(rf\"EXPEDIENTE.*?N[\\s¬∫¬∞o\\.\\-\\¬∞]*{proa_pat}\", re.IGNORECASE | re.DOTALL)\n",
    "        pat_frase = re.compile(r\"Em\\s+an[√°a]lise\\s+aos\\s+autos\\s+e\\s+considerando\\s+as\\s+raz[√µo]es\\s+f[√°a]ticas\\s+e\\s+contratuais\", re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "        for i, page in enumerate(doc):\n",
    "            txt_norm = _norm_text(page.get_text(\"text\"))\n",
    "            if pat_header.search(txt_norm): return i\n",
    "            if pat_frase.search(txt_norm) and proa_notif in txt_norm: return i\n",
    "        doc.close()\n",
    "    except: pass\n",
    "    return -1\n",
    "\n",
    "def _footer_date_from_page(pdf_path: str, page_index: int) -> str:\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        blocks = doc[page_index].get_text(\"blocks\")\n",
    "        cutoff = doc[page_index].rect.height * 0.85\n",
    "        cands = []\n",
    "        for (x0,y0,x1,y1,txt,*_) in blocks:\n",
    "            if y0 >= cutoff:\n",
    "                for m in re.finditer(r\"(\\d{2}/\\d{2}/\\d{4})\", txt):\n",
    "                    cands.append((x0, y0, m.group(1)))\n",
    "        doc.close()\n",
    "        if not cands: return \"\"\n",
    "        cands.sort(key=lambda t: (t[0], -t[1]))\n",
    "        return cands[0][2]\n",
    "    except: return \"\"\n",
    "\n",
    "def get_expediente_text_and_date(pdf_path: str, proa_notif: str) -> tuple:\n",
    "    idx = _find_expediente_page_index(pdf_path, proa_notif)\n",
    "    if idx < 0: return \"\", \"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    txt = _norm_text(doc[idx].get_text(\"text\"))\n",
    "    doc.close()\n",
    "    dt = _footer_date_from_page(pdf_path, idx)\n",
    "    return txt, dt\n",
    "\n",
    "def get_tipo_penalidade(exp_text: str) -> str:\n",
    "    if re.search(r\"\\bMULTA\\b\", exp_text, re.IGNORECASE): return \"multa\"\n",
    "    if re.search(r\"advert(√™|e)ncia\", exp_text, re.IGNORECASE): return \"advertencia\"\n",
    "    if re.search(r\"n[a√£]o\\s+aplica(√ß|c)[a√£]o\\s+de\\s+penalidade\", exp_text, re.IGNORECASE): return \"nao aplicacao de penalidade\"\n",
    "    return ERR_MSG_TIPO_PENALIDADE\n",
    "\n",
    "def get_percentual_multa(exp_text: str) -> str:\n",
    "    # L√≥gica original validada (28/Nov)\n",
    "    words_to_num = {\n",
    "        'zero': 0, 'um': 1, 'uma': 1, 'dois': 2, 'duas': 2, 'tr√™s': 3,\n",
    "        'quatro': 4, 'cinco': 5, 'seis': 6, 'sete': 7, 'oito': 8, 'nove': 9, 'dez': 10\n",
    "    }\n",
    "\n",
    "    # Regex espec√≠fico que funcionou nos testes\n",
    "    m_num = re.search(r\"(?:aplicando\\s+)?multa\\s+(?:de\\s+)?(\\d{1,2})\\s*%\", exp_text, re.IGNORECASE)\n",
    "    m_word = re.search(r\"%\\s*\\(\\s*([^)]+?)\\s+por\\s+cento\\s*\\)\", exp_text, re.IGNORECASE)\n",
    "\n",
    "    if not m_num:\n",
    "        return ERR_MSG_PERCENTUAL_MULTA\n",
    "\n",
    "    # Remove zero √† esquerda (ex: \"05\" -> 5)\n",
    "    num_str = m_num.group(1).lstrip('0') or '0'\n",
    "    num = int(num_str)\n",
    "\n",
    "    if m_word:\n",
    "        word = m_word.group(1).strip().lower()\n",
    "        num_from_word = words_to_num.get(word)\n",
    "\n",
    "        if num_from_word is not None:\n",
    "            # Se houver diverg√™ncia, a l√≥gica original prioriza o extenso (\"mais sensato\")\n",
    "            if num != num_from_word:\n",
    "                return f\"{num_from_word}%\"\n",
    "            return f\"{num}%\"\n",
    "\n",
    "    # Valida√ß√£o simples de range (0 a 10)\n",
    "    return f\"{num}%\" if 0 <= num <= 10 else ERR_MSG_PERCENTUAL_MULTA\n",
    "\n",
    "\n",
    "def get_impedimentos(exp_text: str) -> str:\n",
    "    return \"CFIL/RS\" if re.search(r\"CFIL\\/RS\", exp_text, re.IGNORECASE) else \"\"\n",
    "\n",
    "def get_penalidade_meses(exp_text: str) -> str:\n",
    "    # Helper interno para normalizar texto (mantido da l√≥gica original)\n",
    "    def normalize_word(w: str) -> str:\n",
    "        if not w: return \"\"\n",
    "        # Remove acentos e deixa min√∫sculo\n",
    "        import unicodedata # Mantendo import aqui caso n√£o tenha no global, ou pode mover pra cima\n",
    "        return unicodedata.normalize('NFKD', w.lower()).encode('ascii', 'ignore').decode('utf-8').strip()\n",
    "\n",
    "    words = {\n",
    "        \"um\": 1, \"uma\": 1, \"dois\": 2, \"duas\": 2, \"tres\": 3, \"tre\": 3,\n",
    "        \"quatro\": 4, \"cinco\": 5, \"seis\": 6, \"sete\": 7, \"oito\": 8, \"nove\": 9, \"dez\": 10\n",
    "    }\n",
    "\n",
    "    # 1. Padr√£o Principal (Complexo: contexto de suspens√£o + par√™nteses)\n",
    "    pat = r\"(?:CFIL/RS\\s*,\\s*suspendendo\\s+o\\s+direito\\s+de\\s+licitar\\s+ou\\s+contratar\\s+com\\s+a\\s+Administra√ß√£o\\s*(?:,|pelo)?\\s*)?(?:prazo\\s+de|por)\\s*(\\d{1,2})?\\s*\\(\\s*([^)]+)\\s*\\)?\\s*meses?\"\n",
    "    m = re.search(pat, exp_text, re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "    if m:\n",
    "        num_str = m.group(1)\n",
    "        word_str = m.group(2)\n",
    "        num = 0\n",
    "\n",
    "        if num_str:\n",
    "            num = int(num_str.lstrip('0') or '0')\n",
    "            if word_str:\n",
    "                w = normalize_word(word_str)\n",
    "                # Verifica conflito Digito vs Extenso\n",
    "                for k, v in words.items():\n",
    "                    if re.search(k, w):\n",
    "                        if num != v: num = v # Prioriza extenso\n",
    "                        break\n",
    "        elif word_str:\n",
    "            w = normalize_word(word_str)\n",
    "            for k, v in words.items():\n",
    "                if re.search(k, w):\n",
    "                    num = v\n",
    "                    break\n",
    "            else:\n",
    "                # Se achou texto mas n√£o reconheceu o n√∫mero, falha\n",
    "                pass # Vai cair nos fallbacks ou retornar erro no final\n",
    "\n",
    "        if num > 0:\n",
    "            return \"1 m√™s\" if num == 1 else f\"{num} meses\"\n",
    "\n",
    "    # 2. Fallbacks (L√≥gica sequencial original - n√£o mexi na ordem)\n",
    "\n",
    "    # Fallback 1: \"prazo de 12 mes\"\n",
    "    m1 = re.search(r\"prazo\\s+de\\s+\\(?(\\d{1,2})\\)?\\s+mes\", exp_text, re.IGNORECASE | re.DOTALL)\n",
    "    if m1:\n",
    "        v = int(m1.group(1).lstrip('0') or '0')\n",
    "        return \"1 m√™s\" if v == 1 else f\"{v} meses\"\n",
    "\n",
    "    # Fallback 2: \"prazo de (doze) mes\"\n",
    "    m2 = re.search(r\"prazo\\s+de\\s+\\(([^)]+)\\)\\s+mes\", exp_text, re.IGNORECASE | re.DOTALL)\n",
    "    if m2:\n",
    "        w = normalize_word(m2.group(1))\n",
    "        for k, v in words.items():\n",
    "            if re.search(k, w):\n",
    "                return \"1 m√™s\" if v == 1 else f\"{v} meses\"\n",
    "\n",
    "    # Fallback 3: \"prazo de doze mes\" (sem par√™nteses)\n",
    "    m3 = re.search(r\"prazo\\s+de\\s+([a-z√ß√£√µ√©√™]+)\\s+mes\", exp_text, re.IGNORECASE | re.DOTALL)\n",
    "    if m3:\n",
    "        w = normalize_word(m3.group(1))\n",
    "        for k, v in words.items():\n",
    "            if re.fullmatch(k, w):\n",
    "                return \"1 m√™s\" if v == 1 else f\"{v} meses\"\n",
    "\n",
    "    return ERR_MSG_PENALIDADE_MESES\n",
    "\n",
    "def get_ultima_atualizacao_processo(pdf_path):\n",
    "    # Tenta pegar do rodap√© da √∫ltima p√°gina\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        dt = _footer_date_from_page(pdf_path, len(doc)-1)\n",
    "        doc.close()\n",
    "        if dt: return dt\n",
    "    except: pass\n",
    "    return \"\"\n",
    "\n",
    "def get_data_analise_agora():\n",
    "    return datetime.datetime.now().strftime(\"%d/%m/%Y\")\n",
    "\n",
    "def aplicar_regras_status(data: dict) -> dict:\n",
    "    tipo = data.get(\"tipo_penalidade\", \"\").lower()\n",
    "    if tipo in [\"advertencia\", \"nao aplicacao de penalidade\", ERR_MSG_STATUS]:\n",
    "        data[\"percentual_multa\"] = \"\"\n",
    "        data[\"divida_ativa\"] = \"\"\n",
    "        data[\"penalidade_meses\"] = \"\"\n",
    "    return data\n",
    "\n",
    "# ==========================\n",
    "# EXTRA√á√ÉO DE CAMPOS (CORRIGIDA)\n",
    "# ==========================\n",
    "def extract_fields_from_pdf(pdf_path: str) -> dict:\n",
    "    full_text = extract_pdf_text(pdf_path)\n",
    "    proa_notif = get_proa_notificatorio(full_text)\n",
    "    cnpj_empresa = get_cnpj_empresa(full_text)\n",
    "\n",
    "    # Status Web\n",
    "    status_proa = \"\"\n",
    "    if proa_notif:\n",
    "        num = re.sub(r\"\\D\", \"\", proa_notif)\n",
    "        if num:\n",
    "            print(f\"üîé Consultando status do PROA {num}...\")\n",
    "            time.sleep(1)\n",
    "            status_proa = get_situacao_processo_web(num) or \"\"\n",
    "            print(f\"‚Üí Status: {status_proa}\")\n",
    "\n",
    "    # Expediente\n",
    "    exp_text, quando_aplicada = (\"\", \"\")\n",
    "    if proa_notif:\n",
    "        exp_text, quando_aplicada = get_expediente_text_and_date(pdf_path, proa_notif)\n",
    "\n",
    "    if exp_text:\n",
    "        tipo = get_tipo_penalidade(exp_text)\n",
    "        perc = get_percentual_multa(exp_text)\n",
    "        imp = get_impedimentos(exp_text)\n",
    "        meses = get_penalidade_meses(exp_text)\n",
    "    else:\n",
    "        tipo, perc, imp, meses = ERR_MSG_TIPO_PENALIDADE, ERR_MSG_PERCENTUAL_MULTA, ERR_MSG_IMPEDIMENTOS, ERR_MSG_PENALIDADE_MESES\n",
    "\n",
    "    data = {\n",
    "        \"numero_contrato\": get_numero_contrato(full_text),\n",
    "        \"nome_empresa\": get_nome_empresa(full_text),\n",
    "        \"cnpj_empresa\": cnpj_empresa,\n",
    "        \"proa_notificatorio\": proa_notif,\n",
    "        \"proa_mae\": get_proa_mae(full_text, proa_notif),\n",
    "        \"status_processo\": status_proa,\n",
    "        \"valor_contrato_consolidado\": \"\",\n",
    "        \"tipo_penalidade\": tipo,\n",
    "        \"percentual_multa\": perc,\n",
    "        \"valor_multa\": \"\",\n",
    "        \"impedimentos\": imp,\n",
    "        \"penalidade_meses\": meses,\n",
    "        \"data_penalizacao\": quando_aplicada,\n",
    "        \"ultima_analise_feita\": get_data_analise_agora(),\n",
    "        \"ultima_atualizacao_processo\": get_ultima_atualizacao_processo(pdf_path),\n",
    "    }\n",
    "\n",
    "    data = aplicar_regras_status(data)\n",
    "    for col in COLUMNS: data.setdefault(col, \"\")\n",
    "\n",
    "    return data  # <--- O IMPORTANTE QUE ESTAVA FALTANDO\n",
    "\n",
    "# ==========================\n",
    "# FUN√á√ïES DE PLANILHA E DRIVE (CORRIGIDAS)\n",
    "# ==========================\n",
    "def load_or_create_gsheet(gc, sheet_name, worksheet_name, columns):\n",
    "    try: sh = gc.open(sheet_name)\n",
    "    except: raise Exception(\"Planilha n√£o encontrada.\")\n",
    "    try: ws = sh.worksheet(worksheet_name)\n",
    "    except:\n",
    "        ws = sh.add_worksheet(title=worksheet_name, rows=1, cols=len(columns))\n",
    "        ws.update([columns])\n",
    "        return pd.DataFrame(columns=columns), ws\n",
    "\n",
    "    df = get_as_dataframe(ws, dtype=str)\n",
    "    for col in columns:\n",
    "        if col not in df.columns: df[col] = pd.NA\n",
    "    df = df.fillna(\"\")[columns]\n",
    "    return df, ws\n",
    "\n",
    "def upsert_row(df: pd.DataFrame, row: dict) -> pd.DataFrame:\n",
    "    key_raw = row.get(\"proa_notificatorio\", \"\")\n",
    "    # A chave de busca √© puramente num√©rica\n",
    "    key_clean = re.sub(r\"\\D\", \"\", str(key_raw))\n",
    "\n",
    "    if not key_clean:\n",
    "        return df\n",
    "\n",
    "    # Cria uma s√©rie tempor√°ria s√≥ com os n√∫meros da coluna PROA do DF atual\n",
    "    # Isso garante que vamos achar o processo mesmo se ele estiver como Link\n",
    "    df_proas_clean = df[\"proa_notificatorio\"].apply(_extract_clean_proa)\n",
    "\n",
    "    if key_clean in df_proas_clean.values:\n",
    "        # Pega o √≠ndice da primeira ocorr√™ncia\n",
    "        idx = df_proas_clean[df_proas_clean == key_clean].index[0]\n",
    "\n",
    "        # Atualiza as colunas (mantendo o link antigo se n√£o quisermos for√ßar reescrita,\n",
    "        # mas aqui vamos sobrescrever os dados novos)\n",
    "        for col in COLUMNS:\n",
    "            # S√≥ atualiza se o dado novo n√£o for vazio, ou for√ßa atualiza√ß√£o\n",
    "            val = row.get(col, \"\")\n",
    "            df.at[idx, col] = val\n",
    "    else:\n",
    "        # Se n√£o achou, a√≠ sim cria nova linha\n",
    "        df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def _map_pdf_links_in_folder(drive, folder_id):\n",
    "    \"\"\"Mapeia PDFs com pagina√ß√£o para evitar erro 400.\"\"\"\n",
    "    mapping = {}\n",
    "    page_token = None\n",
    "    print(f\"üìÇ Mapeando Drive ID: {folder_id}...\")\n",
    "    while True:\n",
    "        try:\n",
    "            res = drive.files().list(\n",
    "                q=f\"'{folder_id}' in parents and mimeType='application/pdf' and trashed=false\",\n",
    "                fields=\"nextPageToken, files(id, name, webViewLink)\",\n",
    "                pageSize=1000, pageToken=page_token\n",
    "            ).execute()\n",
    "            for f in res.get(\"files\", []):\n",
    "                link = f.get(\"webViewLink\") or f\"https://drive.google.com/file/d/{f['id']}/view\"\n",
    "                mapping[f[\"name\"]] = link\n",
    "            page_token = res.get('nextPageToken')\n",
    "            if not page_token: break\n",
    "        except Exception as e:\n",
    "            print(f\"Erro no mapeamento: {e}\")\n",
    "            break\n",
    "    print(f\"‚úÖ Arquivos mapeados: {len(mapping)}\")\n",
    "    return mapping\n",
    "\n",
    "def apply_drive_links(df, name_to_link):\n",
    "    \"\"\"Aplica Hyperlinks formato PT-BR (;) nas colunas PROA e Nome.\"\"\"\n",
    "    df_out = df.copy()\n",
    "    if \"proa_notificatorio\" not in df_out.columns: return df_out\n",
    "\n",
    "    # Prepara mapeamento limpo (apenas numeros)\n",
    "    map_clean = {}\n",
    "    for name, link in name_to_link.items():\n",
    "        digits = re.sub(r\"\\D\", \"\", name)\n",
    "        if digits: map_clean[digits] = link\n",
    "\n",
    "    for i, row in df_out.iterrows():\n",
    "        proa = str(row.get(\"proa_notificatorio\", \"\")).strip()\n",
    "        nome = str(row.get(\"nome_empresa\", \"\")).strip()\n",
    "\n",
    "        # Removemos a limpeza aqui dentro para usar a que fizemos l√° fora ou a crua\n",
    "        # Mas para garantir o match do link:\n",
    "        proa_digits = re.sub(r\"\\D\", \"\", proa)\n",
    "\n",
    "        # Tenta achar link\n",
    "        link = \"\"\n",
    "        if proa_digits:\n",
    "            if proa_digits in map_clean:\n",
    "                link = map_clean[proa_digits]\n",
    "            else:\n",
    "                # Tentativa de match parcial (tail)\n",
    "                for w in [14, 12, 10]:\n",
    "                    if len(proa_digits) >= w and proa_digits[-w:] in map_clean:\n",
    "                         link = map_clean[proa_digits[-w:]] # L√≥gica simplificada\n",
    "                         break\n",
    "\n",
    "        if link:\n",
    "             safe_proa = proa.replace('\"', \"'\")\n",
    "             safe_nome = nome.replace('\"', \"'\")\n",
    "\n",
    "             # Se j√° for f√≥rmula, n√£o aplica de novo para n√£o quebrar\n",
    "             if not safe_proa.startswith(\"=HYPERLINK\"):\n",
    "                 df_out.at[i, \"proa_notificatorio\"] = f'=HYPERLINK(\"{link}\"; \"{safe_proa}\")'\n",
    "\n",
    "             if not safe_nome.startswith(\"=HYPERLINK\"):\n",
    "                 df_out.at[i, \"nome_empresa\"] = f'=HYPERLINK(\"{link}\"; \"{safe_nome}\")'\n",
    "\n",
    "             # REMOVIDO: df_out.at[i, \"link_pdf\"] = link\n",
    "\n",
    "    return df_out\n",
    "\n",
    "# ==========================\n",
    "# PIPELINE PRINCIPAL\n",
    "# ==========================\n",
    "# ==========================\n",
    "# PIPELINE PRINCIPAL (L√ìGICA BLINDADA)\n",
    "# ==========================\n",
    "def process_all_pdfs(gc, pdf_dir=PDF_DIR, force_update=False):\n",
    "# 1. Carrega Planilha\n",
    "    df, ws = load_or_create_gsheet(gc, GSHEET_NAME, GSHEET_WORKSHEET_NAME, COLUMNS)\n",
    "\n",
    "    # 2. Mapeia Links do Drive\n",
    "    name_to_link = _map_pdf_links_in_folder(drive, FOLDER_ID_DRIVE)\n",
    "\n",
    "    # 3. Cria Mapa de Datas Existentes (CORRIGIDO PARA LER DENTRO DO HYPERLINK)\n",
    "    existing_dates = {}\n",
    "    if not df.empty and \"proa_notificatorio\" in df.columns:\n",
    "        for _, row in df.iterrows():\n",
    "            # Usa a fun√ß√£o nova para ignorar o =HYPERLINK e pegar s√≥ o n√∫mero\n",
    "            clean_proa = _extract_clean_proa(row[\"proa_notificatorio\"])\n",
    "\n",
    "            d_str = str(row.get(\"ultima_atualizacao_processo\", \"\"))\n",
    "            d_obj = _parse_br_date(d_str)\n",
    "\n",
    "            if clean_proa and d_obj:\n",
    "                existing_dates[clean_proa] = d_obj\n",
    "\n",
    "    print(f\"üìä Processos reconhecidos na planilha: {len(existing_dates)}\")\n",
    "\n",
    "    # 4. Processa PDFs\n",
    "    for fname in os.listdir(pdf_dir):\n",
    "        if not fname.lower().endswith(\".pdf\"): continue\n",
    "        pdf_path = os.path.join(pdf_dir, fname)\n",
    "\n",
    "        should_process = True\n",
    "\n",
    "        # Tenta extrair n√∫meros do nome do arquivo para comparar com a planilha\n",
    "        # Ex: \"Processo_241900.pdf\" -> \"241900\"\n",
    "        proa_digits_pdf = re.sub(r\"\\D\", \"\", fname)\n",
    "\n",
    "        # --- L√ìGICA DE DECIS√ÉO ---\n",
    "        if not force_update:\n",
    "            # CASO 1: Arquivo SEM n√∫meros no nome (n√£o d√° pra saber quem √© sem ler) -> Processa\n",
    "            if not proa_digits_pdf:\n",
    "                should_process = True\n",
    "\n",
    "            # CASO 2: O processo J√Å EST√Å na planilha -> Verifica a data\n",
    "            elif proa_digits_pdf in existing_dates:\n",
    "                data_pdf_str = get_ultima_atualizacao_processo(pdf_path)\n",
    "                data_pdf_obj = _parse_br_date(data_pdf_str)\n",
    "                data_planilha = existing_dates[proa_digits_pdf]\n",
    "\n",
    "                # Se conseguiu ler a data do PDF e ela √© igual ou menor que a da planilha\n",
    "                if data_pdf_obj and data_pdf_obj <= data_planilha:\n",
    "                    print(f\"‚è© Pulando {fname} (J√° atualizado em {data_pdf_str})\")\n",
    "                    should_process = False\n",
    "                else:\n",
    "                    print(f\"üîÑ Atualizando {fname} (Nova data encontrada)\")\n",
    "                    should_process = True\n",
    "\n",
    "            # CASO 3: O processo N√ÉO EST√Å na planilha (Seu caso de teste!)\n",
    "            else:\n",
    "                print(f\"üÜï Novo: {fname} -> Processando...\")\n",
    "                should_process = True\n",
    "\n",
    "        if not should_process:\n",
    "            continue\n",
    "\n",
    "        # --- EXTRA√á√ÉO E SALVAMENTO ---\n",
    "        print(f\"   üìÇ Lendo PDF: {fname}...\")\n",
    "        try:\n",
    "            row = extract_fields_from_pdf(pdf_path)\n",
    "\n",
    "            if row is None:\n",
    "                print(\"   ‚ö†Ô∏è Falha na extra√ß√£o. Pulando.\")\n",
    "                continue\n",
    "\n",
    "            row[\"link_pdf\"] = name_to_link.get(fname, \"\")\n",
    "            df = upsert_row(df, row)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Erro: {e}\")\n",
    "            continue\n",
    "\n",
    "    # 5. Finaliza√ß√£o\n",
    "    df = df[df[\"proa_notificatorio\"].notna() & (df[\"proa_notificatorio\"].str.strip() != \"\")].copy()\n",
    "\n",
    "    # Aplica hyperlinks\n",
    "    df_write = apply_drive_links(df, name_to_link)\n",
    "\n",
    "    print(\"Atualizando planilha...\")\n",
    "    ws.clear()\n",
    "    set_with_dataframe(ws, df_write, include_index=False, resize=True)\n",
    "    print(\"Sucesso! ‚úÖ\")\n",
    "    return df"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==============================================================================\n",
    "# üöÄ EXECU√á√ÉO E DASHBOARD DE MONITORAMENTO\n",
    "# ==============================================================================\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import pandas as pd\n",
    "\n",
    "# Fun√ß√£o para estilizar status com cores\n",
    "def style_status(val):\n",
    "    \"\"\"Colore a c√©lula dependendo do texto do Status\"\"\"\n",
    "    val_str = str(val).lower()\n",
    "    if 'ativo' in val_str:\n",
    "        return 'background-color: #d4edda; color: #155724; font-weight: bold;' # Verde Suave\n",
    "    elif 'erro' in val_str or 'falha' in val_str:\n",
    "        return 'background-color: #f8d7da; color: #721c24; font-weight: bold;' # Vermelho Suave\n",
    "    elif 'arquivado' in val_str or 'encerrado' in val_str:\n",
    "        return 'background-color: #e2e3e5; color: #383d41;' # Cinza\n",
    "    elif val_str == '' or val_str == 'nan':\n",
    "        return 'background-color: #fff3cd; color: #856404;' # Amarelo (Alerta)\n",
    "    return ''\n",
    "\n",
    "try:\n",
    "    # 1. Executa o Pipeline\n",
    "    display(Markdown(\"### ‚öôÔ∏è Iniciando Processamento...\"))\n",
    "    # force_update=True l√™ tudo / False l√™ s√≥ novos e atualizados\n",
    "    df_resultado = process_all_pdfs(gc, force_update=False)\n",
    "\n",
    "    # ----------------------------\n",
    "    # DASHBOARD\n",
    "    # ----------------------------\n",
    "    display(Markdown(\"---\"))\n",
    "    display(Markdown(\"# üìä Painel de Controle: Processo Notificat√≥rio\"))\n",
    "\n",
    "    if df_resultado.empty:\n",
    "        display(Markdown(\"### ‚ö†Ô∏è Nenhum dado foi processado ou a planilha est√° vazia.\"))\n",
    "    else:\n",
    "        # A. KPIs (Indicadores Principais)\n",
    "        total_docs = len(df_resultado)\n",
    "        total_ativos = df_resultado['status_processo'].astype(str).str.contains('Ativo', case=False).sum()\n",
    "        total_erros = df_resultado['status_processo'].astype(str).str.contains('ERRO', case=False).sum()\n",
    "\n",
    "        kpi_html = f\"\"\"\n",
    "        <div style=\"display: flex; gap: 20px; margin-bottom: 20px;\">\n",
    "            <div style=\"background-color: #f8f9fa; padding: 15px; border-radius: 10px; border: 1px solid #ddd; flex: 1; text-align: center;\">\n",
    "                <h2 style=\"margin:0; color: #007bff;\">{total_docs}</h2>\n",
    "                <p style=\"margin:0; color: #666;\">Processos Totais</p>\n",
    "            </div>\n",
    "            <div style=\"background-color: #d4edda; padding: 15px; border-radius: 10px; border: 1px solid #c3e6cb; flex: 1; text-align: center;\">\n",
    "                <h2 style=\"margin:0; color: #155724;\">{total_ativos}</h2>\n",
    "                <p style=\"margin:0; color: #155724;\">Ativos (Web)</p>\n",
    "            </div>\n",
    "            <div style=\"background-color: #f8d7da; padding: 15px; border-radius: 10px; border: 1px solid #f5c6cb; flex: 1; text-align: center;\">\n",
    "                <h2 style=\"margin:0; color: #721c24;\">{total_erros}</h2>\n",
    "                <p style=\"margin:0; color: #721c24;\">Com Erro/Falha</p>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(kpi_html))\n",
    "\n",
    "        # B. Tabela Detalhada (Estilizada)\n",
    "        display(Markdown(\"### üìã Status Detalhado por Processo\"))\n",
    "\n",
    "        cols_status = [\n",
    "            \"proa_notificatorio\", \"status_processo\", \"nome_empresa\",\n",
    "            \"ultima_atualizacao_processo\", \"tipo_penalidade\",\n",
    "            \"percentual_multa\", \"penalidade_meses\", \"divida_ativa\"\n",
    "        ]\n",
    "\n",
    "        # Garante colunas\n",
    "        for c in cols_status:\n",
    "            if c not in df_resultado.columns: df_resultado[c] = \"\"\n",
    "\n",
    "        df_view = (df_resultado[cols_status].copy()\n",
    "                   .sort_values(by=[\"status_processo\", \"proa_notificatorio\"], na_position=\"last\")\n",
    "                   .reset_index(drop=True))\n",
    "\n",
    "        # Aplica estilo (cores condicionais)\n",
    "        styled_table = (df_view.style\n",
    "            .map(style_status, subset=['status_processo'])\n",
    "            .set_properties(**{'text-align': 'left'})\n",
    "            .set_table_styles([{'selector': 'th', 'props': [('text-align', 'left'), ('background-color', '#f1f1f1')]}])\n",
    "        )\n",
    "        display(styled_table)\n",
    "\n",
    "        # C. Distribui√ß√£o e Alertas\n",
    "        display(Markdown(\"### üìà Distribui√ß√£o & Alertas\"))\n",
    "\n",
    "        # Cria dataframe de contagem\n",
    "        contagem = df_resultado[\"status_processo\"].fillna(\"Sem Status\").replace(\"\", \"Sem Status\").value_counts().to_frame(\"Qtd\")\n",
    "\n",
    "        # Barra de dados simples dentro da tabela\n",
    "        display(contagem.style.bar(subset=['Qtd'], color='#5fba7d'))\n",
    "\n",
    "        # D. Alerta de Vazios\n",
    "        sem_status = df_resultado[df_resultado[\"status_processo\"].fillna(\"\") == \"\"]\n",
    "        if not sem_status.empty:\n",
    "            display(Markdown(f\"### ‚ö†Ô∏è ATEN√á√ÉO: {len(sem_status)} Processos sem retorno de status\"))\n",
    "            display(sem_status[[\"proa_notificatorio\", \"nome_empresa\"]].style.hide(axis=\"index\"))\n",
    "        else:\n",
    "            display(Markdown(\"‚úÖ **Sucesso:** Todos os processos possuem status definido.\"))\n",
    "\n",
    "except NameError:\n",
    "    display(Markdown(\"## ‚ùå ERRO CR√çTICO: Vari√°vel `gc` n√£o encontrada\"))\n",
    "    display(Markdown(\"Por favor, rode a c√©lula de **Autentica√ß√£o** no topo do notebook.\"))\n",
    "except Exception as e:\n",
    "    display(Markdown(f\"## ‚ùå Ocorreu um erro inesperado\"))\n",
    "    print(e)"
   ],
   "id": "1650b0287cfab690"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
