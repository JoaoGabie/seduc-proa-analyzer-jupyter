{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ======================INICIO=DO=STATUS===========================================\n",
    "# 1. Instala as bibliotecas necess√°rias\n",
    "!pip install requests beautifulsoup4 --quiet\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def get_situacao_processo_web(processo_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Busca a \"Situa√ß√£o\" de um processo no portal PROA (web scraping).\n",
    "\n",
    "    Args:\n",
    "        processo_id: O n√∫mero do processo (ex: \"24190000141650\").\n",
    "\n",
    "    Returns:\n",
    "        A situa√ß√£o (ex: \"Ativo\") se encontrado.\n",
    "        Uma string de erro (ex: \"ERRO: N√£o encontrado\") se falhar.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Configura√ß√£o da Requisi√ß√£o\n",
    "    base_url = \"https://secweb.procergs.com.br/pra-aj4/public/proa_retorno_consulta_publica.xhtml\"\n",
    "    params = {\"numeroProcesso\": processo_id}\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    # Valor padr√£o em caso de falha\n",
    "    situacao_padrao = \"ERRO: N√£o encontrado\"\n",
    "\n",
    "    try:\n",
    "        # 2. Faz a requisi√ß√£o HTTP\n",
    "        response = requests.get(base_url, params=params, headers=headers, timeout=10)\n",
    "\n",
    "        # Levanta um erro se a p√°gina n√£o for 200 (OK)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # 3. Analisa o HTML\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # 4. L√≥gica de extra√ß√£o\n",
    "        # Encontra a tag <label> que cont√©m o texto \"Situa√ß√£o:\"\n",
    "        situacao_label_tag = soup.find('label', string=re.compile(r\"Situa√ß√£o:\"))\n",
    "\n",
    "        if situacao_label_tag:\n",
    "            # Tenta navegar na tabela para achar o valor\n",
    "            try:\n",
    "                parent_td = situacao_label_tag.find_parent('td')\n",
    "                value_td = parent_td.find_next_sibling('td')\n",
    "                situacao_valor = value_td.get_text(strip=True)\n",
    "\n",
    "                # Retorna o valor limpo se n√£o for vazio\n",
    "                return situacao_valor if situacao_valor else situacao_padrao\n",
    "\n",
    "            except Exception:\n",
    "                # Falha ao navegar na estrutura (ex: HTML mudou)\n",
    "                return \"ERRO: Falha no parse do HTML\"\n",
    "        else:\n",
    "            # N√£o encontrou o label \"Situa√ß√£o:\" na p√°gina\n",
    "            return situacao_padrao\n",
    "\n",
    "    except requests.exceptions.HTTPError:\n",
    "        # Erro HTTP (ex: 404 - N√£o Encontrado, 500 - Erro de Servidor)\n",
    "        return \"ERRO: P√°gina n√£o encontrada ou servidor falhou\"\n",
    "    except requests.exceptions.RequestException:\n",
    "        # Erro de rede (ex: DNS, Timeout, sem internet)\n",
    "        return \"ERRO: Falha na conex√£o\"\n",
    "\n",
    "# ======================FIM=DO=STATUS===========================================\n",
    "\n",
    "!pip install gspread gspread-dataframe google-auth --quiet\n",
    "!pip install pymupdf --quiet\n",
    "\n",
    "# 2. Rode esta c√©lula para autenticar sua conta no Colab\n",
    "# Isso permitir√° que o script acesse seus arquivos do Google\n",
    "from google.colab import auth\n",
    "\n",
    "auth.authenticate_user()\n",
    "\n",
    "# 3. Configure o cliente do gspread\n",
    "import gspread\n",
    "from google.auth import default\n",
    "\n",
    "creds, _ = default()\n",
    "gc = gspread.authorize(creds)\n",
    "\n",
    "# ==========================\n",
    "# CONFIGURA√á√ÉO INICIAL\n",
    "# ==========================\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import fitz  # pymupdf\n",
    "import tiktoken\n",
    "\n",
    "# ====== IMPORTA√á√ïES (Google Sheets) ======\n",
    "import gspread\n",
    "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
    "from google.colab import auth\n",
    "from google.auth import default\n",
    "\n",
    "# ====== CAMINHOS IMPORTANTES ======\n",
    "PDF_DIR = \"/content/drive/MyDrive/processos_cibelle\"  # pasta com os PDFs\n",
    "\n",
    "# ====== CONFIGURA√á√ÉO DO GOOGLE SHEETS ======\n",
    "# O NOME da sua planilha no Google Drive\n",
    "GSHEET_NAME = \"Cibelle_automation\"\n",
    "# O NOME da aba (worksheet) dentro da planilha\n",
    "GSHEET_WORKSHEET_NAME = \"TABELA\"\n",
    "\n",
    "# ======= MENSAGENS DE ERROS ========\n",
    "\n",
    "ERR_MSG_EXPEIDENTE = \"Sem Penalidade\"\n",
    "ERR_MSG_TIPO_PENALIDADE  = \"\"\n",
    "ERR_MSG_PERCENTUAL_MULTA  = \"\"\n",
    "ERR_MSG_IMPEDIMENTOS = \"\"\n",
    "ERR_MSG_PENALIDADE_MESES = \"\"\n",
    "ERR_MSG_DATA_PENALIZACAO = \"\"\n",
    "ERR_MSG_STATUS = \"ERRO: IMPOSSIVEL DE DEFINIR UM STATUS\"\n",
    "# ====== NOME DAS COLUNAS PADR√ÉO ======\n",
    "COLUMNS = [\n",
    "    \"numero_contrato\",\n",
    "    \"nome_empresa\",\n",
    "    \"cnpj_empresa\",\n",
    "    \"proa_notificatorio\",\n",
    "    \"proa_mae\",\n",
    "    \"status_processo\",\n",
    "    \"valor_contrato_consolidado\",\n",
    "    \"tipo_penalidade\",\n",
    "    \"percentual_multa\",\n",
    "    \"valor_multa\",\n",
    "    \"impedimentos\",\n",
    "    \"penalidade_meses\",\n",
    "    \"data_penalizacao\",\n",
    "    \"ultima_analise_feita\",\n",
    "    \"ultima_atualizacao_processo\",\n",
    "    #\"token_input_consumo\",\n",
    "]\n",
    "\n",
    "# ==========================\n",
    "# FUN√á√ÉO: LER TEXTO DO PDF\n",
    "# ==========================\n",
    "def extract_pdf_text(pdf_path: str) -> str:\n",
    "    \"\"\"Extrai TODO o texto do PDF p√°gina a p√°gina e concatena em uma string √∫nica.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages_text = []\n",
    "    for page in doc:\n",
    "        pages_text.append(page.get_text(\"text\"))\n",
    "    full_text = \"\\n\".join(pages_text)\n",
    "    doc.close()\n",
    "    return full_text\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# FUN√á√ÉO: ESTIMAR TOKEN\n",
    "# ==========================\n",
    "def estimate_tokens(text: str, model_name: str = \"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    Estima tokens de entrada de acordo com a tokeniza√ß√£o tiktoken.\n",
    "    Use um modelo aproximado (ex: gpt-4o-mini ou gpt-4o).\n",
    "    Ajuste pro modelo real que voc√™ usar na API.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        enc = tiktoken.encoding_for_model(model_name)\n",
    "    except Exception:\n",
    "        # fallback gen√©rico\n",
    "        enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return len(enc.encode(text))\n",
    "\n",
    "\n",
    "# ==================================\n",
    "# FUN√á√ïES DE EXTRA√á√ÉO (REGEX)\n",
    "# (Estas fun√ß√µes permanecem ID√äNTICAS)\n",
    "# ==================================\n",
    "\n",
    "def _clean_company_name(s: str) -> str:\n",
    "    # colapsa quebras de linha / espa√ßos m√∫ltiplos e remove pontas\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.strip(\" ,;.-\")\n",
    "\n",
    "def _flex_regex_escape(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Cria uma regex flex√≠vel a partir de uma string.\n",
    "    Ex: \"TERMO DE ABERTURA\" vira r\"TERMO\\s+DE\\s+ABERTURA\"\n",
    "    Isso permite encontrar o texto mesmo com quebras de linha ou espa√ßos extras.\n",
    "    \"\"\"\n",
    "    return r\"\\s+\".join(re.escape(part) for part in s.split())\n",
    "\n",
    "def _slice_after_heading(text: str, heading: str, window: int = 1200) -> str:\n",
    "    \"\"\"\n",
    "    Retorna um recorte do texto logo ap√≥s o t√≠tulo/heading (ex: 'TERMO DE ABERTURA'),\n",
    "    limitado por 'window' caracteres para focar no par√°grafo certo.\n",
    "    \"\"\"\n",
    "    # MODIFICADO: Usa a nova fun√ß√£o flex_regex_escape\n",
    "    heading_regex = _flex_regex_escape(heading)\n",
    "    m = re.search(heading_regex, text, flags=re.IGNORECASE)\n",
    "    # FIM DA MODIFICA√á√ÉO\n",
    "\n",
    "    if not m:\n",
    "        return \"\"\n",
    "    start = m.end()\n",
    "    return text[start:start+window]\n",
    "\n",
    "def get_numero_contrato(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai somente 'NNN/AAAA' do n√∫mero do contrato.\n",
    "    Casos:\n",
    "      TERMO DE CONaTRATO EMERGENCIAL ... N¬∞ 371/2023-...\n",
    "      TERMO DE CONTRATO EMERGENCIAL ... N¬∞ 488/2023 - DAL/...\n",
    "      ... N¬∞ 851/2022\n",
    "    Fallback: 'CONTRATO ... N¬∞ NNN/AAAA'\n",
    "    \"\"\"\n",
    "    # alvo principal (TERMO DE CONTRATO EMERGENCIAL ...)\n",
    "    padrao1 = r\"TERMO\\s+DE\\s+CONTRATO\\s+EMERGENCIAL\\s+DE\\s+OBRAS\\s+E\\s+SERVI[√áC]OS\\s+DE\\s+ENGENHARIA\\s*N[¬∫¬∞]?\\s*([0-9]{1,4}/[0-9]{4})\"\n",
    "    m = re.search(padrao1, text, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return m.group(1).strip()\n",
    "\n",
    "    # fallback geral 'CONTRATO ... N¬∞ 123/2023'\n",
    "    padrao2 = r\"CONTRATO[^\\n]{0,120}?N[¬∫¬∞]?\\s*([0-9]{1,4}/[0-9]{4})\"\n",
    "    m2 = re.search(padrao2, text, flags=re.IGNORECASE)\n",
    "    if m2:\n",
    "        return m2.group(1).strip()\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# depois do creds/default() e do gspread:\n",
    "drive = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "def _ensure_public_view_link(drive, file_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Garante que o arquivo tenha permiss√£o 'anyone with the link' como leitor\n",
    "    e retorna o webViewLink no formato .../file/d/<id>/view.\n",
    "    \"\"\"\n",
    "    # 1) tenta ler o webViewLink atual\n",
    "    meta = drive.files().get(fileId=file_id, fields=\"id, webViewLink, permissions\").execute()\n",
    "    link = meta.get(\"webViewLink\")\n",
    "\n",
    "    # 2) se j√° tem link, retorna\n",
    "    if link:\n",
    "        return link\n",
    "\n",
    "    # 3) aplica permiss√£o p√∫blica (se sua organiza√ß√£o permitir)\n",
    "    try:\n",
    "        drive.permissions().create(\n",
    "            fileId=file_id,\n",
    "            body={\"type\": \"anyone\", \"role\": \"reader\"},\n",
    "            fields=\"id\",\n",
    "        ).execute()\n",
    "    except Exception:\n",
    "        # pode falhar em dom√≠nios corporativos com pol√≠ticas de compartilhamento\n",
    "        pass\n",
    "\n",
    "    # 4) tenta de novo pegar o webViewLink\n",
    "    meta2 = drive.files().get(fileId=file_id, fields=\"id, webViewLink\").execute()\n",
    "    link2 = meta2.get(\"webViewLink\")\n",
    "\n",
    "    # 5) fallback: monta manualmente\n",
    "    return link2 or f\"https://drive.google.com/file/d/{file_id}/view\"\n",
    "\n",
    "def _get_folder_id_by_name(drive, folder_name: str) -> str:\n",
    "    resp = drive.files().list(\n",
    "        q=f\"name = '{folder_name}' and mimeType = 'application/vnd.google-apps.folder' and 'root' in parents and trashed = false\",\n",
    "        fields=\"files(id,name)\", pageSize=10\n",
    "    ).execute()\n",
    "    files = resp.get(\"files\", [])\n",
    "    return files[0][\"id\"] if files else \"\"\n",
    "\n",
    "\n",
    "def _map_pdf_links_in_folder(drive, folder_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retorna dict {nome_arquivo.pdf: share_link} garantindo que tenha o /view.\n",
    "    \"\"\"\n",
    "    name_to_link = {}\n",
    "    page_token = None\n",
    "    while True:\n",
    "        resp = drive.files().list(\n",
    "            q=f\"'{folder_id}' in parents and mimeType='application/pdf' and trashed = false\",\n",
    "            fields=\"nextPageToken, files(id,name,webViewLink)\",\n",
    "            pageToken=page_token\n",
    "        ).execute()\n",
    "\n",
    "        for f in resp.get(\"files\", []):\n",
    "            file_id = f[\"id\"]\n",
    "            share_link = f.get(\"webViewLink\") or f\"https://drive.google.com/file/d/{file_id}/view\"\n",
    "            # Se quiser **for√ßar** que fique p√∫blico para qualquer pessoa com o link:\n",
    "            # share_link = _ensure_public_view_link(drive, file_id)\n",
    "            name_to_link[f[\"name\"]] = share_link\n",
    "\n",
    "        page_token = resp.get(\"nextPageToken\")\n",
    "        if not page_token:\n",
    "            break\n",
    "    return name_to_link\n",
    "\n",
    "\n",
    "\n",
    "def get_nome_empresa(text: str) -> str:\n",
    "    \"\"\"\n",
    "    MODIFICADO:\n",
    "    1. Normaliza o texto (com _norm_text) para remover caracteres \"sujos\"\n",
    "    2. Usa regex mais flex√≠vel para parar em (,), (.), (;) ou 'inscrita'\n",
    "    3. A busca pelo \"TERMO DE ABERTURA\" tamb√©m √© flex√≠vel (via _slice_after_heading)\n",
    "    \"\"\"\n",
    "\n",
    "    # MODIFICADO: Normaliza o texto ANTES de qualquer busca\n",
    "    texto_normalizado = _norm_text(text)\n",
    "    # FIM DA MODIFICA√á√ÉO\n",
    "\n",
    "    # 1) bloco ap√≥s TERMO DE ABERTURA\n",
    "    bloco = _slice_after_heading(texto_normalizado, \"TERMO DE ABERTURA\", window=2000)\n",
    "\n",
    "    m = re.search(\n",
    "        r\"inten√ß(?:√£o|ao)\\s+de\\s+instaurar\\s+procedimento\\s+notificat(?:√≥rio|orio)\\s+contra\\s+(?:a\\s+)?empresa\\s+(.+?)(?=[,.;]|inscrita)\",\n",
    "        texto_normalizado,  # Usa o texto j√° normalizado\n",
    "        flags=re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    if m:\n",
    "        return _clean_company_name(m.group(1))\n",
    "\n",
    "    # 2) FALLBACK GEN√âRICO COMBINADO (Novo)\n",
    "    #    Este padr√£o agora junta suas duas ideias:\n",
    "    #    - \\s*[,;]?\\s*: Permite que tenha \"empresa NOME\" OU \"empresa, NOME\"\n",
    "    #    - (?=[,.;]|inscrita): Mant√©m a regra de parada original, que √© mais segura\n",
    "    #\n",
    "    m = re.search(\n",
    "        r\"contra\\s+(?:a\\s+)?empresa\\s*[,;]?\\s*(.+?)(?=[,.;]|inscrita)\",\n",
    "        texto_normalizado,  # Usa o texto j√° normalizado\n",
    "        flags=re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    if m:\n",
    "        return _clean_company_name(m.group(1))\n",
    "    # 4) nada encontrado\n",
    "    return \"ERRO AO ENCONTRAR O NOME DA EMPRESA\"\n",
    "\n",
    "\n",
    "def get_cnpj_empresa(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Mant√©m a l√≥gica antiga, mas:\n",
    "    1) Tenta primeiro ancorado no nome da empresa (get_nome_empresa)\n",
    "    2) Aceita . / - como separadores em qualquer ponto, com \\s* (inclui quebras de linha)\n",
    "    3) Ignora ru√≠do entre 'sob n' e o n√∫mero\n",
    "    4) Se falhar, cai no padr√£o antigo (flex) para n√£o perder recall\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    texto_normalizado = _norm_text(text)\n",
    "    nome = get_nome_empresa(texto_normalizado)\n",
    "    flags = re.IGNORECASE | re.DOTALL\n",
    "\n",
    "    # --- util: nome -> regex flex (espa√ßos, v√≠rgulas/pontos opcionais, LTDAx) ---\n",
    "    def _name_to_regex(n: str) -> str:\n",
    "        # colapsa espa√ßos, permite \\s+ entre palavras e pontua√ß√£o final opcional (LTDA, LTDAA, ME, EPP etc.)\n",
    "        parts = [p for p in re.split(r\"\\s+\", n.strip()) if p]\n",
    "        # cada parte com pontua√ß√£o final opcional\n",
    "        parts = [re.escape(p) + r\"[.,]?\" for p in parts]\n",
    "        # se terminar com LTDA (ou similar), aceita sufuxo de letras (LTDAA)\n",
    "        if parts:\n",
    "            parts[-1] = parts[-1].rstrip(r\"[.,]?\") + r\"[A-Z]{0,2}[.,]?\"\n",
    "        return r\"\\s+\".join(parts)\n",
    "\n",
    "    # CNPJ super flex: aceita . / - (ou nada) entre blocos + \\s* (quebras/espacos)\n",
    "    CNPJ_FLEX = (\n",
    "        r\"(\"                       # captura o CNPJ como um todo\n",
    "        r\"\\d{2}\\s*[\\.\\-]?\\s*\"\n",
    "        r\"\\d{3}\\s*[\\.\\-]?\\s*\"\n",
    "        r\"\\d{3}\\s*[\\./\\-]?\\s*\"\n",
    "        r\"\\d{4}\\s*[\\.\\-\\/]?\\s*\"\n",
    "        r\"\\d{2}\"\n",
    "        r\")\"\n",
    "    )\n",
    "\n",
    "    MIN_FAZENDA = r\"inscrita\\s+no\\s+minist[√©e]rio\\s+da\\s+fazenda\"\n",
    "    # 'sob n' com qualquer ru√≠do n√£o-num√©rico depois (¬∫, ¬∞, o, -, texto), antes dos d√≠gitos\n",
    "    SOB_VARIANTE = r\"sob\\s+(?:o\\s+)?n[^\\d]{0,10}\\s*\"\n",
    "\n",
    "    # 1) Primeiro: padr√£o ancorado no nome\n",
    "    if nome and \"ERRO\" not in nome.upper():\n",
    "        nome_flex = _name_to_regex(nome)\n",
    "        padrao_ancorado = re.compile(\n",
    "            rf\"empresa\\s+{nome_flex}\\s*,?\\s*{MIN_FAZENDA}\\s*{SOB_VARIANTE}{CNPJ_FLEX}\",\n",
    "            flags=flags\n",
    "        )\n",
    "        bloco = _slice_after_heading(texto_normalizado, \"TERMO DE ABERTURA\", window=2000) or \"\"\n",
    "        m = padrao_ancorado.search(bloco) or padrao_ancorado.search(texto_normalizado)\n",
    "        if m:\n",
    "            cnpj_raw = re.sub(r\"\\s+\", \"\", m.group(1))      # tira quebras/espa√ßos\n",
    "            digits = re.sub(r\"\\D\", \"\", cnpj_raw)\n",
    "            return (f\"{digits[0:2]}.{digits[2:5]}.{digits[5:8]}/{digits[8:12]}-{digits[12:14]}\"\n",
    "                    if len(digits) == 14 else \"ERRO AO ENCONTRAR O CNPJ\")\n",
    "\n",
    "    # 2) Fallback: teu padr√£o antigo (com \\s*), mas com separadores flex√≠veis\n",
    "    padrao_flex_antigo = re.compile(\n",
    "        rf\"{MIN_FAZENDA}\\s*{SOB_VARIANTE}{CNPJ_FLEX}\",\n",
    "        flags=flags\n",
    "    )\n",
    "    bloco2 = _slice_after_heading(texto_normalizado, \"TERMO DE ABERTURA\", window=2000) or \"\"\n",
    "    m2 = padrao_flex_antigo.search(bloco2) or padrao_flex_antigo.search(texto_normalizado)\n",
    "    if not m2:\n",
    "        return \"ERRO AO ENCONTRAR O CNPJ\"\n",
    "\n",
    "    cnpj_raw = re.sub(r\"\\s+\", \"\", m2.group(1))\n",
    "    digits = re.sub(r\"\\D\", \"\", cnpj_raw)\n",
    "    return (f\"{digits[0:2]}.{digits[2:5]}.{digits[5:8]}/{digits[8:12]}-{digits[12:14]}\"\n",
    "            if len(digits) == 14 else \"ERRO AO ENCONTRAR O CNPJ\")\n",
    "\n",
    "\n",
    "def get_proa_notificatorio(text: str):\n",
    "    padrao = r\"\\b(\\d{2}\\/\\d{4}-\\d{7}-\\d)\\b\"\n",
    "    ms = re.findall(padrao, text)\n",
    "    return ms[0] if ms else \"\"\n",
    "\n",
    "\n",
    "def get_proa_mae(text: str, proa_atual: str):\n",
    "    padrao = r\"\\b(\\d{2}\\/\\d{4}-\\d{7}-\\d)\\b\"\n",
    "    all_proas = re.findall(padrao, text)\n",
    "    candidates = [p for p in all_proas if p != proa_atual]\n",
    "\n",
    "    def ano(p):\n",
    "        try:\n",
    "            return int(p.split(\"/\")[0])\n",
    "        except:\n",
    "            return 99\n",
    "\n",
    "    if not candidates:\n",
    "        return \"\"\n",
    "    candidates.sort(key=ano)\n",
    "    return candidates[0]\n",
    "\n",
    "def get_expediente_data(pdf_path: str, proa_notif: str) -> dict:\n",
    "    \"\"\"\n",
    "    L√™ SOMENTE a p√°gina 'EXPEDIENTE N¬∫ {proa_notif}' e extrai:\n",
    "      - tipo_penalidade  ('multa' | 'advertencia' | 'nao aplicacao de penalidade')\n",
    "      - percentual_multa ('N%' entre 0 e 10)\n",
    "      - divida_ativa     ('CFIL/RS', 'CADIN/RS' ou 'CFIL/RS; CADIN/RS')\n",
    "      - penalidade_meses ('1 m√™s' / 'N meses')\n",
    "      - quando_multa_aplicada (data dd/mm/aaaa do rodap√© dessa p√°gina)\n",
    "    Caso a p√°gina n√£o exista, retorna ERR_MSG nos 4 campos e '' na data.\n",
    "    \"\"\"\n",
    "    # 1) localizar p√°gina do expediente\n",
    "    page_idx = _find_expediente_page_index(pdf_path, proa_notif)\n",
    "    if page_idx < 0:\n",
    "        return {\n",
    "            \"tipo_penalidade\": ERR_MSG_TIPO_PENALIDADE,\n",
    "            \"percentual_multa\": ERR_MSG_PERCENTUAL_MULTA,\n",
    "            \"impedimentos\": ERR_MSG_IMPEDIMENTOS,\n",
    "            \"penalidade_meses\": ERR_MSG_PENALIDADE_MESES,\n",
    "            \"data_penalizacao\": ERR_MSG_DATA_PENALIZACAO,\n",
    "        }\n",
    "\n",
    "    # 2) texto da p√°gina + data do rodap√© (seus helpers)\n",
    "    page_text = _get_page_text(pdf_path, page_idx)\n",
    "    quando = _footer_date_from_page(pdf_path, page_idx)\n",
    "\n",
    "    # 3) parse dos 4 campos apenas do texto do EXPEDIENTE\n",
    "    # tipo_penalidade\n",
    "    if re.search(r\"\\bMULTA\\b\", page_text, re.IGNORECASE):\n",
    "        tipo = \"Multa\"\n",
    "    elif re.search(r\"advert(√™|e)ncia\", page_text, re.IGNORECASE):\n",
    "        tipo = \"Advertencia\"\n",
    "    elif re.search(r\"n[a√£]o\\s+aplica(√ß|c)[a√£]o\\s+de\\s+penalidade\", page_text, re.IGNORECASE):\n",
    "        tipo = \"N√£o Aplica√ß√£o de penalidade\"\n",
    "    else:\n",
    "        tipo = ERR_MSG_TIPO_PENALIDADE\n",
    "\n",
    "    # percentual_multa (0‚Äì10) com '%'\n",
    "    m = re.search(r\"(?:aplicando\\s+)?multa\\s+(?:de\\s+)?(\\d{1,2})\\s*%\", page_text, re.IGNORECASE)\n",
    "    if m and 0 <= int(m.group(1)) <= 10:\n",
    "        per = f\"{int(m.group(1))}%\"\n",
    "    else:\n",
    "        per = ERR_MSG_PERCENTUAL_MULTA\n",
    "\n",
    "    # divida_ativa (pode ter ambos)\n",
    "    found = []\n",
    "    if re.search(r\"CFIL\\/RS\", page_text, re.IGNORECASE):  found.append(\"CFIL/RS\")\n",
    "    divida = \"; \".join(found) if found else ERR_MSG_IMPEDIMENTOS\n",
    "\n",
    "    # penalidade_meses (n√∫mero ou por extenso)\n",
    "    pen = ERR_MSG_PENALIDADE_MESES\n",
    "    words = {\"um\":1,\"uma\":1,\"dois\":2,\"duas\":2,\"tr[e√™]s\":3,\"tres\":3,\"quatro\":4,\"cinco\":5,\"seis\":6}\n",
    "    m1 = re.search(r\"prazo\\s+de\\s+\\(?(\\d{1,2})\\)?\\s+mes\", page_text, re.IGNORECASE)\n",
    "    if m1:\n",
    "        v = int(m1.group(1)); pen = \"1 m√™s\" if v == 1 else f\"{v} meses\"\n",
    "    else:\n",
    "        m2 = re.search(r\"prazo\\s+de\\s+\\(([^)]+)\\)\\s+mes\", page_text, re.IGNORECASE)\n",
    "        if m2:\n",
    "            w = re.sub(r\"[^a-z√°√©√≠√≥√∫√¢√™√¥√£√µ√ß]\", \"\", m2.group(1).lower())\n",
    "            for k,v in words.items():\n",
    "                if re.search(k, w): pen = \"1 m√™s\" if v == 1 else f\"{v} meses\"; break\n",
    "        if pen == ERR_MSG_PENALIDADE_MESES:\n",
    "            m3 = re.search(r\"prazo\\s+de\\s+([a-z√ß√£√µ√©√™]+)\\s+mes\", page_text, re.IGNORECASE)\n",
    "            if m3:\n",
    "                w = m3.group(1).lower()\n",
    "                for k,v in words.items():\n",
    "                    if re.fullmatch(k, w): pen = \"1 m√™s\" if v == 1 else f\"{v} meses\"; break\n",
    "\n",
    "    return {\n",
    "        \"tipo_penalidade\": tipo,\n",
    "        \"percentual_multa\": per,\n",
    "        \"divida_ativa\": divida,\n",
    "        \"penalidade_meses\": pen,\n",
    "        \"quando_multa_aplicada\": quando,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_tipo_penalidade(exp_text: str) -> str:\n",
    "    if re.search(r\"\\bMULTA\\b\", exp_text, re.IGNORECASE):\n",
    "        return \"multa\"\n",
    "    if re.search(r\"advert(√™|e)ncia\", exp_text, re.IGNORECASE):\n",
    "        return \"advertencia\"\n",
    "    if re.search(r\"n[a√£]o\\s+aplica(√ß|c)[a√£]o\\s+de\\s+penalidade\", exp_text, re.IGNORECASE):\n",
    "        return \"nao aplicacao de penalidade\"\n",
    "    return ERR_MSG_TIPO_PENALIDADE\n",
    "\n",
    "\n",
    "def get_percentual_multa(exp_text: str) -> str:\n",
    "    # Dicion√°rio para converter n√∫meros por extenso em portugu√™s\n",
    "    words_to_num = {\n",
    "        'zero': 0,\n",
    "        'um': 1, 'uma': 1,\n",
    "        'dois': 2, 'duas': 2,\n",
    "        'tr√™s': 3,\n",
    "        'quatro': 4,\n",
    "        'cinco': 5,\n",
    "        'seis': 6,\n",
    "        'sete': 7,\n",
    "        'oito': 8,\n",
    "        'nove': 9,\n",
    "        'dez': 10\n",
    "    }\n",
    "\n",
    "    # Regex para num√©rico: \"multa de 05 %\"\n",
    "    m_num = re.search(r\"(?:aplicando\\s+)?multa\\s+(?:de\\s+)?(\\d{1,2})\\s*%\", exp_text, re.IGNORECASE)\n",
    "    # Regex para por extenso: \"(cinco por cento)\" logo ap√≥s\n",
    "    m_word = re.search(r\"%\\s*\\(\\s*([^)]+?)\\s+por\\s+cento\\s*\\)\", exp_text, re.IGNORECASE)\n",
    "\n",
    "    if not m_num:\n",
    "        return ERR_MSG_PERCENTUAL_MULTA\n",
    "\n",
    "    num_str = m_num.group(1).lstrip('0') or '0'  # Remove leading zero: \"05\" -> \"5\"\n",
    "    num = int(num_str)\n",
    "\n",
    "    if m_word:\n",
    "        word = m_word.group(1).strip().lower()\n",
    "        num_from_word = words_to_num.get(word)\n",
    "        if num_from_word is not None:\n",
    "            # Se bater (considerando leading zero), usa o valor\n",
    "            if num == num_from_word:\n",
    "                return f\"{num}%\"\n",
    "            else:\n",
    "                # Discrep√¢ncia: prioriza por extenso como \"mais sensato\"\n",
    "                return f\"{num_from_word}%\"\n",
    "\n",
    "    # Se n√£o houver por extenso ou n√£o mapear, retorna o num√©rico ajustado\n",
    "    return f\"{num}%\" if 0 <= num <= 10 else \"ERRO NA PORCENTAGEM: MAIOR QUE 10%\"\n",
    "\n",
    "def get_impedimentos(exp_text: str) -> str:\n",
    "    found = []\n",
    "    if re.search(r\"CFIL\\/RS\", exp_text, re.IGNORECASE):\n",
    "        found.append(\"CFIL/RS\")\n",
    "    return \"; \".join(found) if found else ERR_MSG_IMPEDIMENTOS\n",
    "\n",
    "\n",
    "def get_penalidade_meses(exp_text: str) -> str:\n",
    "    import re\n",
    "    import unicodedata\n",
    "\n",
    "    # Normaliza palavra para remover acentos e lower\n",
    "    def normalize_word(w: str) -> str:\n",
    "        w = unicodedata.normalize('NFKD', w.lower()).encode('ascii', 'ignore').decode('utf-8')\n",
    "        return w.strip()\n",
    "\n",
    "    # Dicion√°rio expandido\n",
    "    words = {\n",
    "        \"um\": 1, \"uma\": 1,\n",
    "        \"dois\": 2, \"duas\": 2,\n",
    "        \"tres\": 3, \"tre\": 3,\n",
    "        \"quatro\": 4,\n",
    "        \"cinco\": 5,\n",
    "        \"seis\": 6,\n",
    "        \"sete\": 7,\n",
    "        \"oito\": 8,\n",
    "        \"nove\": 9,\n",
    "        \"dez\": 10\n",
    "    }\n",
    "\n",
    "    # Padr√£o principal: captura frases antes, \"prazo de\" ou \"por\", n√∫mero/extenso/combinado\n",
    "    pat = r\"(?:CFIL/RS\\s*,\\s*suspendendo\\s+o\\s+direito\\s+de\\s+licitar\\s+ou\\s+contratar\\s+com\\s+a\\s+Administra√ß√£o\\s*(?:,|pelo)?\\s*)?(?:prazo\\s+de|por)\\s*(\\d{1,2})?\\s*\\(\\s*([^)]+)\\s*\\)?\\s*meses?\"\n",
    "    m = re.search(pat, exp_text, re.IGNORECASE | re.DOTALL)\n",
    "    if m:\n",
    "        num_str = m.group(1)\n",
    "        word_str = m.group(2)\n",
    "\n",
    "        if num_str:\n",
    "            num = int(num_str.lstrip('0') or '0')\n",
    "            if word_str:\n",
    "                w = normalize_word(word_str)\n",
    "                for k, v in words.items():\n",
    "                    if re.search(k, w):\n",
    "                        # Verifica se bate; se n√£o, usa extenso (mais sensato)\n",
    "                        if num != v:\n",
    "                            num = v\n",
    "                        break\n",
    "        elif word_str:\n",
    "            w = normalize_word(word_str)\n",
    "            for k, v in words.items():\n",
    "                if re.search(k, w):\n",
    "                    num = v\n",
    "                    break\n",
    "            else:\n",
    "                return ERR_MSG_PENALIDADE_MESES\n",
    "        else:\n",
    "            return ERR_MSG_PENALIDADE_MESES\n",
    "\n",
    "        return \"1 m√™s\" if num == 1 else f\"{num} meses\"\n",
    "\n",
    "    # Fallbacks originais para padr√µes simples\n",
    "    m1 = re.search(r\"prazo\\s+de\\s+\\(?(\\d{1,2})\\)?\\s+mes\", exp_text, re.IGNORECASE | re.DOTALL)\n",
    "    if m1:\n",
    "        v = int(m1.group(1).lstrip('0') or '0')\n",
    "        return \"1 m√™s\" if v == 1 else f\"{v} meses\"\n",
    "\n",
    "    m2 = re.search(r\"prazo\\s+de\\s+\\(([^)]+)\\)\\s+mes\", exp_text, re.IGNORECASE | re.DOTALL)\n",
    "    if m2:\n",
    "        w = normalize_word(m2.group(1))\n",
    "        for k, v in words.items():\n",
    "            if re.search(k, w):\n",
    "                return \"1 m√™s\" if v == 1 else f\"{v} meses\"\n",
    "\n",
    "    m3 = re.search(r\"prazo\\s+de\\s+([a-z√ß√£√µ√©√™]+)\\s+mes\", exp_text, re.IGNORECASE | re.DOTALL)\n",
    "    if m3:\n",
    "        w = normalize_word(m3.group(1))\n",
    "        for k, v in words.items():\n",
    "            if re.fullmatch(k, w):\n",
    "                return \"1 m√™s\" if v == 1 else f\"{v} meses\"\n",
    "\n",
    "    return ERR_MSG_TIPO_PENALIDADE\n",
    "\n",
    "def get_expediente_text_and_date(pdf_path: str, proa_notif: str) -> tuple[str, str]:\n",
    "    idx = _find_expediente_page_index(pdf_path, proa_notif)\n",
    "    if idx < 0:\n",
    "        return \"\", \"\"\n",
    "    exp_text = _get_page_text(pdf_path, idx)\n",
    "    exp_text = _norm_text(exp_text)            # <-- aqui\n",
    "    quando = _footer_date_from_page(pdf_path, idx)\n",
    "    return exp_text, quando\n",
    "\n",
    "def _norm_text(s: str) -> str:\n",
    "    # normaliza espa√ßos e h√≠fens ‚Äúestranhos‚Äù\n",
    "    s = (s.replace(\"\\xa0\", \" \")   # NBSP\n",
    "           .replace(\"\\u2009\", \" \") # thin space\n",
    "           .replace(\"\\u200a\", \" \")\n",
    "           .replace(\"\\u200b\", \"\")  # zero-width\n",
    "           .replace(\"‚Äì\", \"-\")\n",
    "           .replace(\"‚Äî\", \"-\")\n",
    "           .replace(\"-\", \"-\"))     # non-breaking hyphen\n",
    "    # colapsa espa√ßos m√∫ltiplos\n",
    "    s = re.sub(r\"[ \\t]+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "def _build_proa_regex(proa_notif: str) -> str:\n",
    "    # Ex: 19/1900-0050962-6 ‚Üí permite espa√ßos, quebras, h√≠fens\n",
    "    parts = re.split(r'[/-]', proa_notif)\n",
    "    if len(parts) != 4:\n",
    "        return re.escape(proa_notif)\n",
    "    a, b, c, d = [p.strip() for p in parts]\n",
    "    return rf\"{a}\\s*/\\s*{b}\\s*-\\s*{c.lstrip('0')}\\s*-\\s*{d}\"\n",
    "\n",
    "def _find_expediente_page_index(pdf_path: str, proa_notif: str) -> int:\n",
    "    import fitz, re\n",
    "\n",
    "    # 1. Primeiro tenta pelo EXPEDIENTE N¬∞ (com seu _norm_text)\n",
    "    proa_pat = _build_proa_regex(proa_notif)\n",
    "    header_pat = rf\"EXPEDIENTE.*?N[\\s¬∫¬∞o\\.\\-\\¬∞]*{proa_pat}\"\n",
    "    pat_header = re.compile(header_pat, re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "    # 2. Fallback: frase padr√£o (flex√≠vel com \\s+)\n",
    "    frase_flex = r\"Em\\s+an[√°a]lise\\s+aos\\s+autos\\s+e\\s+considerando\\s+as\\s+raz[√µo]es\\s+f[√°a]ticas\\s+e\\s+contratuais\"\n",
    "    pat_frase = re.compile(frase_flex, re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        for i, page in enumerate(doc):\n",
    "            txt = page.get_text(\"text\")\n",
    "            txt_norm = _norm_text(txt)\n",
    "\n",
    "            # Estrat√©gia 1: EXPEDIENTE N¬∞\n",
    "            if pat_header.search(txt_norm):\n",
    "                return i\n",
    "\n",
    "            # Estrat√©gia 2: Frase (s√≥ se tiver o PROA na mesma p√°gina)\n",
    "            if pat_frase.search(txt_norm) and proa_notif in txt_norm:\n",
    "                return i\n",
    "\n",
    "        doc.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return -1\n",
    "\n",
    "\n",
    "\n",
    "def _get_page_text(pdf_path: str, page_index: int) -> str:\n",
    "    import fitz\n",
    "    doc = fitz.open(pdf_path)\n",
    "    txt = doc[page_index].get_text(\"text\")\n",
    "    doc.close()\n",
    "    return txt\n",
    "\n",
    "def _footer_date_from_page(pdf_path: str, page_index: int, bottom_pct: float = 0.85) -> str:\n",
    "    import fitz, re\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        page = doc[page_index]\n",
    "        blocks = page.get_text(\"blocks\")\n",
    "        h = page.rect.height\n",
    "        cutoff = h * bottom_pct\n",
    "        cands = []\n",
    "        for (x0,y0,x1,y1,txt,*_) in blocks:\n",
    "            if y0 >= cutoff:\n",
    "                for m in re.finditer(r\"(\\d{2}/\\d{2}/\\d{4})(?:\\s+\\d{2}:\\d{2}:\\d{2})?\", txt):\n",
    "                    cands.append((x0, y0, m.group(1)))\n",
    "        doc.close()\n",
    "        if not cands: return \"\"\n",
    "        cands.sort(key=lambda t: (t[0], -t[1]))  # mais √† esquerda\n",
    "        return cands[0][2]\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def get_quando_multa_aplicada(pdf_path: str, proa_notif: str) -> str:\n",
    "    \"\"\"\n",
    "    Data mostrada no rodap√© da p√°gina do EXPEDIENTE N¬∫ {proa}.\n",
    "    \"\"\"\n",
    "    idx = _find_expediente_page_index(pdf_path, proa_notif)\n",
    "    if idx < 0:\n",
    "        return \"\"\n",
    "    return _footer_date_from_page(pdf_path, idx)\n",
    "\n",
    "def get_ultima_atualizacao_processo(pdf_path_or_text):\n",
    "    \"\"\"\n",
    "    Extrai a data da √∫ltima atualiza√ß√£o do processo.\n",
    "    1) Tenta ler o rodap√© da √∫ltima p√°gina do PDF (campo √† esquerda, ex: '09/07/2025 17:59:14').\n",
    "    2) Se n√£o encontrar, busca pela data mais recente no texto.\n",
    "    \"\"\"\n",
    "    padrao_data = r\"\\b(\\d{1,2}[\\/\\.]\\d{1,2}[\\/\\.]\\d{4})\\b\"\n",
    "\n",
    "    # ======== tentativa 1: rodap√© da √∫ltima p√°gina ========\n",
    "    try:\n",
    "        if os.path.exists(pdf_path_or_text):  # √© um arquivo PDF\n",
    "            doc = fitz.open(pdf_path_or_text)\n",
    "            page = doc[-1]\n",
    "            blocks = page.get_text(\"blocks\")\n",
    "            page_h = page.rect.height\n",
    "            cutoff_y = page_h * 0.85  # parte inferior (rodap√©)\n",
    "            datas_footer = []\n",
    "            for b in blocks:\n",
    "                x0, y0, x1, y1, txt = b[:5]\n",
    "                if y0 >= cutoff_y:\n",
    "                    for m in re.finditer(r\"(\\d{2}/\\d{2}/\\d{4})(?:\\s+\\d{2}:\\d{2}:\\d{2})?\", txt):\n",
    "                        datas_footer.append((x0, y0, m.group(1)))\n",
    "            doc.close()\n",
    "            if datas_footer:\n",
    "                # escolhe a mais √† esquerda (menor x0)\n",
    "                datas_footer.sort(key=lambda t: (t[0], -t[1]))\n",
    "                return datas_footer[0][2]\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # ======== tentativa 2: busca no texto ========\n",
    "    # se o argumento for texto, usa direto; sen√£o tenta ler texto do PDF\n",
    "    if os.path.exists(pdf_path_or_text):\n",
    "        try:\n",
    "            doc = fitz.open(pdf_path_or_text)\n",
    "            text = \"\\n\".join(page.get_text(\"text\") for page in doc)\n",
    "            doc.close()\n",
    "        except Exception:\n",
    "            text = \"\"\n",
    "    else:\n",
    "        text = pdf_path_or_text\n",
    "\n",
    "    datas = re.findall(padrao_data, text)\n",
    "    if not datas:\n",
    "        return \"\"\n",
    "\n",
    "    valid_dates = []\n",
    "    for d_str in datas:\n",
    "        d_str_norm = d_str.replace(\".\", \"/\")\n",
    "        try:\n",
    "            dd, mm, yyyy = map(int, d_str_norm.split(\"/\"))\n",
    "            valid_dates.append((datetime.date(yyyy, mm, dd), d_str_norm))\n",
    "        except ValueError:\n",
    "            continue\n",
    "    if not valid_dates:\n",
    "        return \"\"\n",
    "\n",
    "    valid_dates.sort(key=lambda x: x[0], reverse=True)\n",
    "    return valid_dates[0][1]\n",
    "\n",
    "\n",
    "\n",
    "def get_data_analise_agora():\n",
    "    hoje = datetime.datetime.now().strftime(\"%d/%m/%Y\")\n",
    "    return hoje\n",
    "\n",
    "STATUS_SEM_CALCULO = {\n",
    "    \"advertencia\",\n",
    "    \"nao aplicacao de penalidade\",\n",
    "    ERR_MSG_STATUS  # \"ERRO: n√£o encontrado o EXPEDIENTE\"\n",
    "}\n",
    "\n",
    "def aplicar_regras_status(data: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Aplica regra de neg√≥cio:\n",
    "    Se tipo_penalidade ‚àà STATUS_SEM_CALCULO ‚Üí limpa percentual, d√≠vida, meses.\n",
    "    \"\"\"\n",
    "    tipo = data.get(\"tipo_penalidade\", \"\").lower().strip()\n",
    "\n",
    "    if tipo in STATUS_SEM_CALCULO:\n",
    "        data[\"percentual_multa\"] = \"\"\n",
    "        data[\"divida_ativa\"] = \"\"\n",
    "        data[\"penalidade_meses\"] = \"\"\n",
    "\n",
    "    return data\n",
    "\n",
    "# ==========================\n",
    "# EXTRA√á√ÉO DE CAMPOS (1 PDF)\n",
    "# (Esta fun√ß√£o permanece ID√äNTICA)\n",
    "# ==========================\n",
    "def extract_fields_from_pdf(pdf_path: str) -> dict:\n",
    "    import re, time\n",
    "\n",
    "    full_text = extract_pdf_text(pdf_path)\n",
    "    tokens_estimados = estimate_tokens(full_text)\n",
    "    proa_notif = get_proa_notificatorio(full_text)\n",
    "    cnpj_empresa = get_cnpj_empresa(full_text)\n",
    "    valor_contrato = \"\"\n",
    "    valor_multa = \"\"\n",
    "\n",
    "    # =========== STATUS DO PROCESSO (WEB) ===========\n",
    "    status_proa = \"\"\n",
    "    if proa_notif:\n",
    "        # Remove tudo que n√£o √© d√≠gito ‚Üí 23/1900-0050521-5 ‚Üí 23190000505215\n",
    "        proa_num_raw = re.sub(r\"\\D\", \"\", proa_notif)\n",
    "        if proa_num_raw:\n",
    "            print(f\"üîé Consultando status do PROA {proa_num_raw}...\")\n",
    "            time.sleep(3)  # delay para respeitar o servidor\n",
    "            status_proa = get_situacao_processo_web(proa_num_raw) or \"\"\n",
    "            print(f\"‚Üí Status retornado: {status_proa}\\n\")\n",
    "\n",
    "    # ============= DEBUG OPCIONAL =============\n",
    "    NOME_DO_ARQUIVO_QUE_FALHA = \"ANALUZA\"  # ajuste se quiser logar um PDF espec√≠fico\n",
    "    if NOME_DO_ARQUIVO_QUE_FALHA.lower() in pdf_path.lower():\n",
    "        print(f\"\\n\\n--- DEBUGGING PDF: {pdf_path} ---\")\n",
    "        texto_normalizado_debug = _norm_text(full_text)\n",
    "        bloco_termo_abertura_debug = _slice_after_heading(texto_normalizado_debug, \"TERMO DE ABERTURA\", window=2000)\n",
    "        print(\"--- BLOCO 'TERMO DE ABERTURA' (visto pelo script): ---\")\n",
    "        print(repr(bloco_termo_abertura_debug))\n",
    "        print(\"-----------------------------------------------------\\n\\n\")\n",
    "\n",
    "    # ===== EXPEDIENTE =====\n",
    "    exp_text, quando_aplicada = (\"\", \"\")\n",
    "    if proa_notif:\n",
    "        exp_text, quando_aplicada = get_expediente_text_and_date(pdf_path, proa_notif)\n",
    "\n",
    "    if exp_text:\n",
    "        tipo_penalidade  = get_tipo_penalidade(exp_text)\n",
    "        percentual_multa = get_percentual_multa(exp_text)\n",
    "        impedimentos     = get_impedimentos(exp_text)\n",
    "        penalidade_meses = get_penalidade_meses(exp_text)\n",
    "    else:\n",
    "        tipo_penalidade  = ERR_MSG_TIPO_PENALIDADE\n",
    "        percentual_multa = ERR_MSG_PERCENTUAL_MULTA\n",
    "        impedimentos     = ERR_MSG_IMPEDIMENTOS\n",
    "        penalidade_meses = ERR_MSG_PENALIDADE_MESES\n",
    "\n",
    "    data = {\n",
    "        \"numero_contrato\":             get_numero_contrato(full_text),\n",
    "        \"nome_empresa\":                get_nome_empresa(full_text),\n",
    "        \"cnpj_empresa\":                cnpj_empresa,\n",
    "        \"proa_notificatorio\":          proa_notif,\n",
    "        \"proa_mae\":                    get_proa_mae(full_text, proa_notif),\n",
    "        \"status_processo\":             status_proa,                 # <-- status agora vem da web\n",
    "        \"valor_contrato_consolidado\":  valor_contrato,  # -> vazio por enquanto\n",
    "        \"tipo_penalidade\":             tipo_penalidade,\n",
    "        \"percentual_multa\":            percentual_multa,\n",
    "        \"valor_multa\":                 valor_multa, # -> vazio por enquanto\n",
    "        \"impedimentos\":                impedimentos,\n",
    "        \"penalidade_meses\":            penalidade_meses,\n",
    "        \"data_penalizacao\":            quando_aplicada,\n",
    "        \"ultima_analise_feita\":        get_data_analise_agora(),\n",
    "        \"ultima_atualizacao_processo\": get_ultima_atualizacao_processo(pdf_path),\n",
    "        #\"token_input_consumo\":         tokens_estimados, -> removido por enquanto\n",
    "    }\n",
    "\n",
    "    # Regras de neg√≥cio: limpa campos de multa quando n√£o aplic√°vel\n",
    "    data = aplicar_regras_status(data)\n",
    "\n",
    "    # Garante todas as colunas esperadas\n",
    "    for col in COLUMNS:\n",
    "        data.setdefault(col, \"\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# FUN√á√ÉO: CARREGAR / CRIAR PLANILHA (MODIFICADA)\n",
    "# ==========================\n",
    "def load_or_create_gsheet(gc: gspread.Client, sheet_name: str, worksheet_name: str, columns: list[str]) -> tuple[\n",
    "    pd.DataFrame, gspread.Worksheet]:\n",
    "    \"\"\"\n",
    "    Carrega uma planilha Google Sheets. Se a aba (worksheet) n√£o existir, cria.\n",
    "    Retorna o DataFrame e o objeto worksheet.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Abre a Planilha (Spreadsheet)\n",
    "        sh = gc.open(sheet_name)\n",
    "    except gspread.exceptions.SpreadsheetNotFound:\n",
    "        print(f\"ERRO: Planilha '{sheet_name}' n√£o encontrada.\")\n",
    "        print(\"Por favor, crie a planilha no Google Sheets e compartilhe com o e-mail da sua conta Colab.\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # 2. Abre a Aba (Worksheet)\n",
    "        ws = sh.worksheet(worksheet_name)\n",
    "    except gspread.exceptions.WorksheetNotFound:\n",
    "        # Cria a aba se n√£o existir\n",
    "        print(f\"Aviso: Aba '{worksheet_name}' n√£o encontrada. Criando...\")\n",
    "        ws = sh.add_worksheet(title=worksheet_name, rows=1, cols=len(columns))\n",
    "        # Define o cabe√ßalho\n",
    "        ws.update([columns])\n",
    "        # Retorna um DF vazio, pois acabamos de criar\n",
    "        return pd.DataFrame(columns=columns), ws\n",
    "\n",
    "    # 3. Se a aba existe, carrega os dados para o pandas\n",
    "    # Usamos gspread_dataframe para facilitar\n",
    "    df = get_as_dataframe(ws, dtype=str)\n",
    "\n",
    "    # 4. Garante que todas as colunas esperadas existam (mesma l√≥gica de antes)\n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = pd.NA  # Use pd.NA para valores nulos consistentes\n",
    "\n",
    "    # Converte pd.NA para string vazia \"\" para consist√™ncia com gspread\n",
    "    df = df.fillna(\"\")\n",
    "\n",
    "    # 5. Reordena/filtra para manter apenas as colunas esperadas\n",
    "    df = df[columns]\n",
    "\n",
    "    return df, ws\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# FUN√á√ÉO: ATUALIZAR/INSERIR LINHA\n",
    "# (Esta fun√ß√£o permanece ID√äNTICA)\n",
    "# ==========================\n",
    "def upsert_row(df: pd.DataFrame, row: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Se j√° existir mesma 'proa_notificatorio', atualiza.\n",
    "    Sen√£o, adiciona nova linha.\n",
    "    Se n√£o tem proa_notificatorio, n√£o insere (evita linha vazia).\n",
    "    \"\"\"\n",
    "    key = row.get(\"proa_notificatorio\", \"\").strip()\n",
    "\n",
    "    if key == \"\":\n",
    "        print(\"‚ö† Aviso: PDF ignorado porque n√£o foi poss√≠vel extrair proa_notificatorio.\")\n",
    "        return df\n",
    "\n",
    "    # Converte a coluna do df para string para garantir a compara√ß√£o\n",
    "    df[\"proa_notificatorio\"] = df[\"proa_notificatorio\"].astype(str)\n",
    "\n",
    "    if key in df[\"proa_notificatorio\"].values:\n",
    "        idx = df.index[df[\"proa_notificatorio\"] == key][0]\n",
    "        for col in COLUMNS:\n",
    "            df.at[idx, col] = row.get(col, df.at[idx, col])\n",
    "    else:\n",
    "        df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# PIPELINE COMPLETO (MODIFICADO)\n",
    "# ==========================\n",
    "def process_all_pdfs(gc: gspread.Client, pdf_dir=PDF_DIR, gsheet_name=GSHEET_NAME,\n",
    "                     worksheet_name=GSHEET_WORKSHEET_NAME):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o principal que orquestra todo o processo.\n",
    "    Agora tamb√©m aplica hyperlink no PROA se link do Drive existir.\n",
    "    \"\"\"\n",
    "    # 1. Carrega / cria a planilha\n",
    "    df, ws = load_or_create_gsheet(gc, gsheet_name, worksheet_name, COLUMNS)\n",
    "\n",
    "    # 2. Mapear PDFs da pasta no Drive -> link\n",
    "    folder_name = os.path.basename(PDF_DIR.rstrip(\"/\"))\n",
    "    folder_id = _get_folder_id_by_name(drive, folder_name)\n",
    "    name_to_link = _map_pdf_links_in_folder(drive, folder_id) if folder_id else {}\n",
    "\n",
    "    # 3. Processa PDFs\n",
    "    for fname in os.listdir(pdf_dir):\n",
    "        if not fname.lower().endswith(\".pdf\"):\n",
    "            continue\n",
    "\n",
    "        pdf_path = os.path.join(pdf_dir, fname)\n",
    "        print(f\"Processando: {pdf_path}\")\n",
    "\n",
    "        try:\n",
    "            row = extract_fields_from_pdf(pdf_path)\n",
    "            df = upsert_row(df, row)\n",
    "        except Exception as e:\n",
    "            print(f\"ERRO ao processar o PDF {fname}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # 4. Mant√©m s√≥ linhas com PROA\n",
    "    df = df[df[\"proa_notificatorio\"].notna() & (df[\"proa_notificatorio\"].str.strip() != \"\")].copy()\n",
    "\n",
    "    # 5. Criar vers√£o com hyperlinks\n",
    "    df_to_write = df.copy()\n",
    "\n",
    "    for i, row in df_to_write.iterrows():\n",
    "        proa_val = row.get(\"proa_notificatorio\", \"\").strip()\n",
    "        fname = f\"{proa_val}.pdf\"  # voc√™ pode ajustar se o nome do arquivo for diferente\n",
    "        texto = proa_val\n",
    "\n",
    "        try:\n",
    "            link = name_to_link.get(fname, \"\")\n",
    "            if link and texto:\n",
    "                df_to_write.at[i, \"proa_notificatorio\"] = f'=HYPERLINK(\"{link}\"; \"{texto}\")'\n",
    "        except Exception as e:\n",
    "            # fallback: se algo der errado, deixa s√≥ o nome\n",
    "            df_to_write.at[i, \"proa_notificatorio\"] = texto\n",
    "\n",
    "    # 6. Escrever no Google Sheets\n",
    "    print(f\"Atualizando Google Sheet '{gsheet_name}'...\")\n",
    "    ws.clear()\n",
    "    set_with_dataframe(ws, df_to_write, include_index=False, resize=True)\n",
    "\n",
    "    # 7. Remover valida√ß√£o antiga\n",
    "    sh = gc.open(gsheet_name)\n",
    "    sheet_id = ws.id\n",
    "    col_index = COLUMNS.index(\"percentual_multa\") + 1\n",
    "    col_0based = col_index - 1\n",
    "\n",
    "    requests = {\n",
    "        \"requests\": [\n",
    "            {\n",
    "                \"setDataValidation\": {\n",
    "                    \"range\": {\n",
    "                        \"sheetId\": sheet_id,\n",
    "                        \"startRowIndex\": 0,\n",
    "                        \"startColumnIndex\": col_0based,\n",
    "                        \"endColumnIndex\": col_0based + 1\n",
    "                    },\n",
    "                    \"rule\": None\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    sh.batch_update(requests)\n",
    "    print(f\"Valida√ß√£o removida da coluna {chr(64 + col_index)} ‚úÖ\")\n",
    "    print(\"Planilha atualizada com sucesso! ‚úÖ\")\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==========================\n",
    "# EXECU√á√ÉO (atualizado p/ mostrar STATUS)\n",
    "# ==========================\n",
    "# 1) Garanta que os PDFs est√£o em PDF_DIR (ex.: /content/drive/MyDrive/processos_cibelle)\n",
    "# 2) Garanta que voc√™ j√° rodou a C√âLULA DE AUTENTICA√á√ÉO e que a vari√°vel 'gc' existe.\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "try:\n",
    "    # Roda o pipeline completo (l√™ PDFs, extrai dados e atualiza a planilha)\n",
    "    df_resultado = process_all_pdfs(gc)\n",
    "\n",
    "    print(\"\\n‚úÖ Pipeline conclu√≠do. Amostra do DataFrame consolidado:\")\n",
    "    display(df_resultado.head(10))\n",
    "\n",
    "    # ----------------------------\n",
    "    # VIS√ÉO FOCADA EM STATUS\n",
    "    # ----------------------------\n",
    "    cols_status = [\n",
    "        \"proa_notificatorio\",\n",
    "        \"status_processo\",\n",
    "        \"nome_empresa\",\n",
    "        \"ultima_atualizacao_processo\",\n",
    "        \"tipo_penalidade\",\n",
    "        \"percentual_multa\",\n",
    "        \"penalidade_meses\",\n",
    "        \"divida_ativa\",\n",
    "    ]\n",
    "\n",
    "    # Garante colunas caso estejam vazias\n",
    "    for c in cols_status:\n",
    "        if c not in df_resultado.columns:\n",
    "            df_resultado[c] = \"\"\n",
    "\n",
    "    # Tabela resumida: PROA x STATUS (ordenado por PROA)\n",
    "    df_status = (\n",
    "        df_resultado[cols_status]\n",
    "        .copy()\n",
    "        .sort_values(by=[\"status_processo\", \"proa_notificatorio\"], na_position=\"last\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(\"\\nüìã Status por processo (PROA):\")\n",
    "    display(df_status)\n",
    "\n",
    "    # Contagem por status (distribui√ß√£o)\n",
    "    print(\"\\nüìä Distribui√ß√£o de status:\")\n",
    "    contagem = df_resultado[\"status_processo\"].fillna(\"\").replace(\"\", \"‚Äî (vazio)\").value_counts()\n",
    "    display(contagem.to_frame(\"quantidade\"))\n",
    "\n",
    "    # Lista r√°pida de processos sem status retornado\n",
    "    sem_status = df_resultado[df_resultado[\"status_processo\"].fillna(\"\") == \"\"]\n",
    "    if not sem_status.empty:\n",
    "        print(\"\\n‚ö†Ô∏è Processos sem status retornado (pode ser erro no site/consulta):\")\n",
    "        display(sem_status[[\"proa_notificatorio\", \"nome_empresa\"]])\n",
    "\n",
    "except NameError:\n",
    "    print(\"\\nERRO: A vari√°vel 'gc' n√£o foi definida.\")\n",
    "    print(\"Por favor, rode a c√©lula de autentica√ß√£o do Google Colab (no in√≠cio) antes de executar este bloco.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nOcorreu um erro inesperado: {e}\")\n",
    "    print(\"Verifique se o nome da planilha est√° correto e se ela est√° compartilhada.\")\n"
   ],
   "id": "1650b0287cfab690"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
